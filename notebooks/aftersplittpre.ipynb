{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e2709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Data Loaded Successfully!\n",
      "Training data shape: (5000, 20)\n",
      "Test data shape: (500, 19)\n",
      "\n",
      "📊 Training Data Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_Id</th>\n",
       "      <th>Supplier_Name</th>\n",
       "      <th>Supplier_Reliability</th>\n",
       "      <th>Equipment_Height</th>\n",
       "      <th>Equipment_Width</th>\n",
       "      <th>Equipment_Weight</th>\n",
       "      <th>Equipment_Type</th>\n",
       "      <th>Equipment_Value</th>\n",
       "      <th>Base_Transport_Fee</th>\n",
       "      <th>CrossBorder_Shipping</th>\n",
       "      <th>Urgent_Shipping</th>\n",
       "      <th>Installation_Service</th>\n",
       "      <th>Transport_Method</th>\n",
       "      <th>Fragile_Equipment</th>\n",
       "      <th>Hospital_Info</th>\n",
       "      <th>Rural_Hospital</th>\n",
       "      <th>Order_Placed_Date</th>\n",
       "      <th>Delivery_Date</th>\n",
       "      <th>Hospital_Location</th>\n",
       "      <th>Transport_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fffe3200360030003700</td>\n",
       "      <td>Jo Valencia</td>\n",
       "      <td>0.44</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.62</td>\n",
       "      <td>17.13</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>10/20/17</td>\n",
       "      <td>10/20/17</td>\n",
       "      <td>APO AA 33776</td>\n",
       "      <td>179.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fffe3400380037003400</td>\n",
       "      <td>Wanda Warren</td>\n",
       "      <td>0.58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1210684.0</td>\n",
       "      <td>Marble</td>\n",
       "      <td>9703.37</td>\n",
       "      <td>35.42</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>02/22/16</td>\n",
       "      <td>02/24/16</td>\n",
       "      <td>South Kevin, VT 84493</td>\n",
       "      <td>627732.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fffe3200350036003700</td>\n",
       "      <td>Robert Ackies</td>\n",
       "      <td>0.97</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>Aluminium</td>\n",
       "      <td>40.21</td>\n",
       "      <td>18.54</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>01/11/18</td>\n",
       "      <td>01/10/18</td>\n",
       "      <td>Kevinshire, NE 31279</td>\n",
       "      <td>1565.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffe3800320034003400</td>\n",
       "      <td>Charlotte Membreno</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>Brass</td>\n",
       "      <td>4.55</td>\n",
       "      <td>17.48</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>08/06/16</td>\n",
       "      <td>08/06/16</td>\n",
       "      <td>DPO AP 61572</td>\n",
       "      <td>257.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fffe3600340033003000</td>\n",
       "      <td>Nena Silva</td>\n",
       "      <td>0.66</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marble</td>\n",
       "      <td>2726.80</td>\n",
       "      <td>30.23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/15/16</td>\n",
       "      <td>12/17/16</td>\n",
       "      <td>Joshuamouth, AK 01550</td>\n",
       "      <td>8553.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hospital_Id       Supplier_Name  Supplier_Reliability  \\\n",
       "0  fffe3200360030003700         Jo Valencia                  0.44   \n",
       "1  fffe3400380037003400        Wanda Warren                  0.58   \n",
       "2  fffe3200350036003700       Robert Ackies                  0.97   \n",
       "3  fffe3800320034003400  Charlotte Membreno                  0.70   \n",
       "4  fffe3600340033003000          Nena Silva                  0.66   \n",
       "\n",
       "   Equipment_Height  Equipment_Width  Equipment_Weight Equipment_Type  \\\n",
       "0              21.0              6.0               NaN            NaN   \n",
       "1              29.0             20.0         1210684.0         Marble   \n",
       "2              39.0             15.0            3305.0      Aluminium   \n",
       "3               8.0              5.0             606.0          Brass   \n",
       "4              27.0             13.0               NaN         Marble   \n",
       "\n",
       "   Equipment_Value  Base_Transport_Fee CrossBorder_Shipping Urgent_Shipping  \\\n",
       "0             3.62               17.13                   No              No   \n",
       "1          9703.37               35.42                   No             Yes   \n",
       "2            40.21               18.54                   No              No   \n",
       "3             4.55               17.48                   No              No   \n",
       "4          2726.80               30.23                  Yes              No   \n",
       "\n",
       "  Installation_Service Transport_Method Fragile_Equipment  Hospital_Info  \\\n",
       "0                   No         Roadways                No  Working Class   \n",
       "1                  Yes         Roadways                No  Working Class   \n",
       "2                   No         Roadways                No  Working Class   \n",
       "3                   No         Roadways                No  Working Class   \n",
       "4                   No         Roadways                No  Working Class   \n",
       "\n",
       "  Rural_Hospital Order_Placed_Date Delivery_Date      Hospital_Location  \\\n",
       "0             No          10/20/17      10/20/17           APO AA 33776   \n",
       "1             No          02/22/16      02/24/16  South Kevin, VT 84493   \n",
       "2             No          01/11/18      01/10/18   Kevinshire, NE 31279   \n",
       "3             No          08/06/16      08/06/16           DPO AP 61572   \n",
       "4            NaN          12/15/16      12/17/16  Joshuamouth, AK 01550   \n",
       "\n",
       "   Transport_Cost  \n",
       "0          179.50  \n",
       "1       627732.45  \n",
       "2         1565.92  \n",
       "3          257.71  \n",
       "4         8553.52  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1: LOAD DATA\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data from data folder\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"📂 Data Loaded Successfully!\")\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n📊 Training Data Preview:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ee6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features Prepared!\n",
      "Feature columns: 16\n",
      "Training samples: 5000\n",
      "\n",
      "Feature names:\n",
      "['Supplier_Name', 'Supplier_Reliability', 'Equipment_Height', 'Equipment_Width', 'Equipment_Weight', 'Equipment_Type', 'Equipment_Value', 'Base_Transport_Fee', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service', 'Transport_Method', 'Fragile_Equipment', 'Hospital_Info', 'Rural_Hospital', 'Hospital_Location']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: PREPARE FEATURES\n",
    "# ============================================\n",
    "\n",
    "# Drop columns that won't be used for modeling\n",
    "columns_to_drop = ['Hospital_Id', 'Order_Placed_Date', 'Delivery_Date']\n",
    "\n",
    "# Separate features and target from training data\n",
    "X = train_df.drop(columns=columns_to_drop + ['Transport_Cost'])\n",
    "y = train_df['Transport_Cost']\n",
    "\n",
    "# Prepare test data (no target variable)\n",
    "X_submission = test_df.drop(columns=columns_to_drop)\n",
    "test_ids = test_df['Hospital_Id']\n",
    "\n",
    "print(\"✅ Features Prepared!\")\n",
    "print(f\"Feature columns: {X.shape[1]}\")\n",
    "print(f\"Training samples: {X.shape[0]}\")\n",
    "print(f\"\\nFeature names:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c982b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Train-Test Split Complete!\n",
      "Training set: 4000 samples (80.0%)\n",
      "Test set: 1000 samples (20.0%)\n",
      "\n",
      "Target variable statistics:\n",
      "  Train mean: $20,866.69\n",
      "  Train std: $284,531.95\n",
      "  Test mean: $6,023.55\n",
      "  Test std: $47,122.21\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3: TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "# Split the data (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"📊 Train-Test Split Complete!\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"  Train mean: ${y_train.mean():,.2f}\")\n",
    "print(f\"  Train std: ${y_train.std():,.2f}\")\n",
    "print(f\"  Test mean: ${y_test.mean():,.2f}\")\n",
    "print(f\"  Test std: ${y_test.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93aa2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "\n",
    "# ============================================\n",
    "# POST-SPLIT PREPROCESSING PIPELINE\n",
    "# ============================================\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train=None):\n",
    "    \"\"\"\n",
    "    Robust preprocessing pipeline for medical equipment transport cost prediction.\n",
    "    \n",
    "    Steps:\n",
    "    1. Handle missing values (mean/median/mode)\n",
    "    2. Handle skewness (log transformation)\n",
    "    3. Scale features (StandardScaler)\n",
    "    4. Encode categorical variables\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features (before preprocessing)\n",
    "    - X_test: Test features (before preprocessing)\n",
    "    - y_train: Training target (for log transformation if needed)\n",
    "    \n",
    "    Returns:\n",
    "    - X_train_processed, X_test_processed, y_train_processed (if provided)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create copies to avoid modifying original data\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    # ============================================\n",
    "    # 1. SEPARATE FEATURES BY TYPE\n",
    "    # ============================================\n",
    "    \n",
    "    # Numerical features\n",
    "    numerical_features = [\n",
    "        'Supplier_Reliability', 'Equipment_Height', 'Equipment_Width', \n",
    "        'Equipment_Weight', 'Equipment_Value', 'Base_Transport_Fee', \n",
    "        'Delivery_Days'\n",
    "    ]\n",
    "    \n",
    "    # Categorical features\n",
    "    categorical_features = [\n",
    "        'Supplier_Name', 'Equipment_Type', 'Transport_Method',\n",
    "        'CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',\n",
    "        'Fragile_Equipment', 'Hospital_Info', 'Rural_Hospital', 'Hospital_Location'\n",
    "    ]\n",
    "    \n",
    "    # ============================================\n",
    "    # 2. HANDLE MISSING VALUES - NUMERICAL\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"📊 Handling Missing Values...\")\n",
    "    \n",
    "    # For skewed numerical features -> use MEDIAN\n",
    "    skewed_features = ['Equipment_Weight', 'Equipment_Value', 'Base_Transport_Fee']\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        if col in X_train.columns:\n",
    "            if col in skewed_features:\n",
    "                # Use median for skewed features\n",
    "                train_median = X_train[col].median()\n",
    "                X_train[col].fillna(train_median, inplace=True)\n",
    "                X_test[col].fillna(train_median, inplace=True)\n",
    "            else:\n",
    "                # Use mean for normally distributed features\n",
    "                train_mean = X_train[col].mean()\n",
    "                X_train[col].fillna(train_mean, inplace=True)\n",
    "                X_test[col].fillna(train_mean, inplace=True)\n",
    "    \n",
    "    # ============================================\n",
    "    # 3. HANDLE MISSING VALUES - CATEGORICAL\n",
    "    # ============================================\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in X_train.columns:\n",
    "            # Use MODE (most frequent value)\n",
    "            train_mode = X_train[col].mode()[0] if not X_train[col].mode().empty else 'Unknown'\n",
    "            X_train[col].fillna(train_mode, inplace=True)\n",
    "            X_test[col].fillna(train_mode, inplace=True)\n",
    "    \n",
    "    # ============================================\n",
    "    # 4. HANDLE SKEWNESS - LOG TRANSFORMATION\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"📈 Handling Skewness...\")\n",
    "    \n",
    "    # Apply log transformation to highly skewed features\n",
    "    # Add 1 to avoid log(0) issues\n",
    "    highly_skewed = ['Equipment_Weight', 'Equipment_Value', 'Base_Transport_Fee']\n",
    "    \n",
    "    for col in highly_skewed:\n",
    "        if col in X_train.columns:\n",
    "            # Check if column has positive values\n",
    "            if (X_train[col] > 0).all():\n",
    "                X_train[col] = np.log1p(X_train[col])  # log(1+x)\n",
    "                X_test[col] = np.log1p(X_test[col])\n",
    "            else:\n",
    "                # If has zeros or negatives, add minimum value + 1\n",
    "                min_val = X_train[col].min()\n",
    "                if min_val <= 0:\n",
    "                    shift = abs(min_val) + 1\n",
    "                    X_train[col] = np.log1p(X_train[col] + shift)\n",
    "                    X_test[col] = np.log1p(X_test[col] + shift)\n",
    "    \n",
    "    # ============================================\n",
    "    # 5. ENCODE CATEGORICAL VARIABLES\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"🔤 Encoding Categorical Variables...\")\n",
    "    \n",
    "    # Label Encoding for categorical features\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in X_train.columns:\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Fit on training data\n",
    "            X_train[col] = X_train[col].astype(str)\n",
    "            X_test[col] = X_test[col].astype(str)\n",
    "            \n",
    "            # Get all unique categories from both train and test\n",
    "            all_categories = pd.concat([X_train[col], X_test[col]]).unique()\n",
    "            le.fit(all_categories)\n",
    "            \n",
    "            # Transform\n",
    "            X_train[col] = le.transform(X_train[col])\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "            \n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # ============================================\n",
    "    # 6. SCALE FEATURES - STANDARDIZATION\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"⚖️ Scaling Features...\")\n",
    "    \n",
    "    # StandardScaler for all numerical features (including encoded categoricals)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit on training data only\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    X_train_processed = pd.DataFrame(\n",
    "        X_train_scaled, \n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_test_processed = pd.DataFrame(\n",
    "        X_test_scaled, \n",
    "        columns=X_test.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    \n",
    "    # ============================================\n",
    "    # 7. HANDLE TARGET VARIABLE (if provided)\n",
    "    # ============================================\n",
    "    \n",
    "    y_train_processed = None\n",
    "    if y_train is not None:\n",
    "        y_train_processed = y_train.copy()\n",
    "        \n",
    "        # Check if target is skewed (optional: apply log transformation)\n",
    "        skewness = stats.skew(y_train_processed)\n",
    "        \n",
    "        if abs(skewness) > 1:  # If highly skewed\n",
    "            print(f\"⚠️ Target variable is skewed (skewness: {skewness:.2f})\")\n",
    "            print(\"   Applying log transformation to target...\")\n",
    "            y_train_processed = np.log1p(y_train_processed)\n",
    "    \n",
    "    print(\"✅ Preprocessing Complete!\")\n",
    "    print(f\"   Training shape: {X_train_processed.shape}\")\n",
    "    print(f\"   Test shape: {X_test_processed.shape}\")\n",
    "    \n",
    "    # Return processed data and fitted objects for future use\n",
    "    results = {\n",
    "        'X_train': X_train_processed,\n",
    "        'X_test': X_test_processed,\n",
    "        'y_train': y_train_processed,\n",
    "        'scaler': scaler,\n",
    "        'label_encoders': label_encoders\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================\n",
    "\n",
    "# Assuming you have already split your data:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, ...)\n",
    "\n",
    "# Apply preprocessing\n",
    "# results = preprocess_data(X_train, X_test, y_train)\n",
    "\n",
    "# Extract processed data\n",
    "# X_train_processed = results['X_train']\n",
    "# X_test_processed = results['X_test']\n",
    "# y_train_processed = results['y_train']\n",
    "\n",
    "# For making predictions on new data later:\n",
    "# scaler = results['scaler']\n",
    "# label_encoders = results['label_encoders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e23b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Starting Preprocessing Pipeline...\n",
      "\n",
      "📊 Handling Missing Values...\n",
      "📈 Handling Skewness...\n",
      "🔤 Encoding Categorical Variables...\n",
      "⚖️ Scaling Features...\n",
      "✅ Preprocessing Complete!\n",
      "   Training shape: (4000, 16)\n",
      "   Test shape: (1000, 16)\n",
      "\n",
      "📦 Preprocessed Data Summary:\n",
      "X_train shape: (4000, 16)\n",
      "X_test shape: (1000, 16)\n",
      "y_train shape: (4000,)\n",
      "y_train NaN count: 0\n",
      "\n",
      "Sample of preprocessed features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supplier_Name</th>\n",
       "      <th>Supplier_Reliability</th>\n",
       "      <th>Equipment_Height</th>\n",
       "      <th>Equipment_Width</th>\n",
       "      <th>Equipment_Weight</th>\n",
       "      <th>Equipment_Type</th>\n",
       "      <th>Equipment_Value</th>\n",
       "      <th>Base_Transport_Fee</th>\n",
       "      <th>CrossBorder_Shipping</th>\n",
       "      <th>Urgent_Shipping</th>\n",
       "      <th>Installation_Service</th>\n",
       "      <th>Transport_Method</th>\n",
       "      <th>Fragile_Equipment</th>\n",
       "      <th>Hospital_Info</th>\n",
       "      <th>Rural_Hospital</th>\n",
       "      <th>Hospital_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>1.020988</td>\n",
       "      <td>-1.312871e+00</td>\n",
       "      <td>0.527965</td>\n",
       "      <td>0.071885</td>\n",
       "      <td>-0.837113</td>\n",
       "      <td>1.596695</td>\n",
       "      <td>-0.774738</td>\n",
       "      <td>-1.054930</td>\n",
       "      <td>1.411302</td>\n",
       "      <td>1.424082</td>\n",
       "      <td>1.23695</td>\n",
       "      <td>-1.354274</td>\n",
       "      <td>-0.436030</td>\n",
       "      <td>-1.675082</td>\n",
       "      <td>2.171241</td>\n",
       "      <td>-1.322553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>-0.903351</td>\n",
       "      <td>-1.832738e+00</td>\n",
       "      <td>1.639633</td>\n",
       "      <td>2.182058</td>\n",
       "      <td>2.389144</td>\n",
       "      <td>0.648680</td>\n",
       "      <td>2.224475</td>\n",
       "      <td>1.648837</td>\n",
       "      <td>-0.708566</td>\n",
       "      <td>1.424082</td>\n",
       "      <td>-0.80844</td>\n",
       "      <td>0.123788</td>\n",
       "      <td>2.293421</td>\n",
       "      <td>-1.675082</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>-0.023474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.177778</td>\n",
       "      <td>-9.929528e-01</td>\n",
       "      <td>-1.524347</td>\n",
       "      <td>-1.079119</td>\n",
       "      <td>-1.347175</td>\n",
       "      <td>-1.247351</td>\n",
       "      <td>-0.678970</td>\n",
       "      <td>-0.483329</td>\n",
       "      <td>-0.708566</td>\n",
       "      <td>-0.702207</td>\n",
       "      <td>1.23695</td>\n",
       "      <td>-1.354274</td>\n",
       "      <td>-0.436030</td>\n",
       "      <td>0.596986</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>-1.654602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>-0.530379</td>\n",
       "      <td>1.886309e+00</td>\n",
       "      <td>-1.524347</td>\n",
       "      <td>-1.079119</td>\n",
       "      <td>-1.502645</td>\n",
       "      <td>-1.247351</td>\n",
       "      <td>-0.629338</td>\n",
       "      <td>-0.304239</td>\n",
       "      <td>-0.708566</td>\n",
       "      <td>-0.702207</td>\n",
       "      <td>-0.80844</td>\n",
       "      <td>-1.354274</td>\n",
       "      <td>-0.436030</td>\n",
       "      <td>0.596986</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.133192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>-1.684983</td>\n",
       "      <td>-2.219877e-16</td>\n",
       "      <td>0.698991</td>\n",
       "      <td>1.222889</td>\n",
       "      <td>0.587493</td>\n",
       "      <td>-0.299336</td>\n",
       "      <td>0.456636</td>\n",
       "      <td>0.242517</td>\n",
       "      <td>-0.708566</td>\n",
       "      <td>-0.702207</td>\n",
       "      <td>1.23695</td>\n",
       "      <td>0.123788</td>\n",
       "      <td>-0.436030</td>\n",
       "      <td>0.596986</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>1.218069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Supplier_Name  Supplier_Reliability  Equipment_Height  Equipment_Width  \\\n",
       "4227       1.020988         -1.312871e+00          0.527965         0.071885   \n",
       "4676      -0.903351         -1.832738e+00          1.639633         2.182058   \n",
       "800        0.177778         -9.929528e-01         -1.524347        -1.079119   \n",
       "3671      -0.530379          1.886309e+00         -1.524347        -1.079119   \n",
       "4193      -1.684983         -2.219877e-16          0.698991         1.222889   \n",
       "\n",
       "      Equipment_Weight  Equipment_Type  Equipment_Value  Base_Transport_Fee  \\\n",
       "4227         -0.837113        1.596695        -0.774738           -1.054930   \n",
       "4676          2.389144        0.648680         2.224475            1.648837   \n",
       "800          -1.347175       -1.247351        -0.678970           -0.483329   \n",
       "3671         -1.502645       -1.247351        -0.629338           -0.304239   \n",
       "4193          0.587493       -0.299336         0.456636            0.242517   \n",
       "\n",
       "      CrossBorder_Shipping  Urgent_Shipping  Installation_Service  \\\n",
       "4227              1.411302         1.424082               1.23695   \n",
       "4676             -0.708566         1.424082              -0.80844   \n",
       "800              -0.708566        -0.702207               1.23695   \n",
       "3671             -0.708566        -0.702207              -0.80844   \n",
       "4193             -0.708566        -0.702207               1.23695   \n",
       "\n",
       "      Transport_Method  Fragile_Equipment  Hospital_Info  Rural_Hospital  \\\n",
       "4227         -1.354274          -0.436030      -1.675082        2.171241   \n",
       "4676          0.123788           2.293421      -1.675082       -0.460566   \n",
       "800          -1.354274          -0.436030       0.596986       -0.460566   \n",
       "3671         -1.354274          -0.436030       0.596986       -0.460566   \n",
       "4193          0.123788          -0.436030       0.596986       -0.460566   \n",
       "\n",
       "      Hospital_Location  \n",
       "4227          -1.322553  \n",
       "4676          -0.023474  \n",
       "800           -1.654602  \n",
       "3671           0.133192  \n",
       "4193           1.218069  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 4: APPLY PREPROCESSING PIPELINE (SIMPLIFIED)\n",
    "# ============================================\n",
    "\n",
    "print(\"🔄 Starting Preprocessing Pipeline...\\n\")\n",
    "\n",
    "# DON'T pass y_train to preprocessing - we'll handle it separately\n",
    "results = preprocess_data(X_train, X_test, y_train=None)\n",
    "\n",
    "# Extract preprocessed data\n",
    "X_train_processed = results['X_train']\n",
    "X_test_processed = results['X_test']\n",
    "\n",
    "# Use ORIGINAL y_train (no transformation)\n",
    "y_train_processed = y_train.copy()\n",
    "\n",
    "# Save the scaler and encoders for later use\n",
    "scaler = results['scaler']\n",
    "label_encoders = results['label_encoders']\n",
    "\n",
    "print(\"\\n📦 Preprocessed Data Summary:\")\n",
    "print(f\"X_train shape: {X_train_processed.shape}\")\n",
    "print(f\"X_test shape: {X_test_processed.shape}\")\n",
    "print(f\"y_train shape: {y_train_processed.shape}\")\n",
    "print(f\"y_train NaN count: {y_train_processed.isna().sum()}\")\n",
    "\n",
    "print(f\"\\nSample of preprocessed features:\")\n",
    "display(X_train_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf87574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Training Baseline Model: Linear Regression\n",
      "\n",
      "Training samples after removing NaN: 4000\n",
      "✅ Model trained successfully!\n",
      "\n",
      "============================================================\n",
      "📈 BASELINE MODEL PERFORMANCE - LINEAR REGRESSION\n",
      "============================================================\n",
      "\n",
      "🎯 TRAINING SET:\n",
      "   RMSE: $273,100.45\n",
      "   MAE:  $63,258.27\n",
      "   R²:   0.0785\n",
      "\n",
      "🎯 TEST SET:\n",
      "   RMSE: $75,414.20\n",
      "   MAE:  $52,528.90\n",
      "   R²:   -1.5638\n",
      "\n",
      "📊 Overfitting Check:\n",
      "   RMSE Difference: $197,686.24\n",
      "   R² Difference: 1.6423\n",
      "   ❌ Significant overfitting detected\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5: BASELINE MODEL - LINEAR REGRESSION (SIMPLE)\n",
    "# ============================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"🤖 Training Baseline Model: Linear Regression\\n\")\n",
    "\n",
    "# Remove any rows where target is NaN\n",
    "valid_indices = ~y_train_processed.isna()\n",
    "X_train_clean = X_train_processed[valid_indices]\n",
    "y_train_clean = y_train_processed[valid_indices]\n",
    "\n",
    "print(f\"Training samples after removing NaN: {len(y_train_clean)}\")\n",
    "\n",
    "# Initialize and train the model\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "print(\"✅ Model trained successfully!\\n\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = baseline_model.predict(X_train_clean)\n",
    "y_test_pred = baseline_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_clean, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train_clean, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train_clean, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"📈 BASELINE MODEL PERFORMANCE - LINEAR REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n🎯 TRAINING SET:\")\n",
    "print(f\"   RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"   MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"   R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 TEST SET:\")\n",
    "print(f\"   RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"   MAE:  ${test_mae:,.2f}\")\n",
    "print(f\"   R²:   {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n📊 Overfitting Check:\")\n",
    "print(f\"   RMSE Difference: ${abs(train_rmse - test_rmse):,.2f}\")\n",
    "print(f\"   R² Difference: {abs(train_r2 - test_r2):.4f}\")\n",
    "\n",
    "if abs(train_r2 - test_r2) < 0.05:\n",
    "    print(\"   ✅ Model generalizes well!\")\n",
    "elif abs(train_r2 - test_r2) < 0.1:\n",
    "    print(\"   ⚠️ Slight overfitting detected\")\n",
    "else:\n",
    "    print(\"   ❌ Significant overfitting detected\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
