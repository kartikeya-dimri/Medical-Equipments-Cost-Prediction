{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4eb9bb",
   "metadata": {},
   "source": [
    "### 📋 Preprocessing Summary\n",
    "\n",
    "* **Filtered bad data** by removing rows with a negative `Transport_Cost`.\n",
    "* **Engineered `Equipment_Volume`** by multiplying `Height` and `Width`.\n",
    "* **Cleaned `Delivery_Days`** by keeping all values (distinguishing them from same-day `0`).\n",
    "* **Normalized features** by log-transforming skewed inputs (`Value`, `Volume`, `Weight`, `Base_Transport_Fee`).\n",
    "* **Normalized the target** by applying a log-transform (`np.log1p`) to `Transport_Cost`.\n",
    "* **Removed clutter** by dropping all ID, redundant, and original date columns.\n",
    "* **Split the data** into an 80% training set and a 20% test set.\n",
    "* **Established a baseline** by calculating the dollar-scale RMSE of just guessing the mean cost.\n",
    "* **Built a numeric pipeline** to impute missing values with the `median` and scale with `RobustScaler` (handles outliers).\n",
    "* **Built a categorical pipeline** to impute missing values with the `most_frequent` and apply `OneHotEncoder`.\n",
    "* **Prevented data leakage** by `fitting` the preprocessor *only* on the training data and then `transforming` both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "818f43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data + plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from scipy.stats import zscore\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# sklearn (preprocessing / pipeline / model selection / metrics)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, PowerTransformer,RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# classical models (if you use them elsewhere)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# gradient boosting / lightgbm / xgboost\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# utilities\n",
    "import joblib   # optional: save/load pipeline\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b39d4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_Id</th>\n",
       "      <th>Supplier_Name</th>\n",
       "      <th>Supplier_Reliability</th>\n",
       "      <th>Equipment_Height</th>\n",
       "      <th>Equipment_Width</th>\n",
       "      <th>Equipment_Weight</th>\n",
       "      <th>Equipment_Type</th>\n",
       "      <th>Equipment_Value</th>\n",
       "      <th>Base_Transport_Fee</th>\n",
       "      <th>CrossBorder_Shipping</th>\n",
       "      <th>Urgent_Shipping</th>\n",
       "      <th>Installation_Service</th>\n",
       "      <th>Transport_Method</th>\n",
       "      <th>Fragile_Equipment</th>\n",
       "      <th>Hospital_Info</th>\n",
       "      <th>Rural_Hospital</th>\n",
       "      <th>Order_Placed_Date</th>\n",
       "      <th>Delivery_Date</th>\n",
       "      <th>Hospital_Location</th>\n",
       "      <th>Transport_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fffe3200360030003700</td>\n",
       "      <td>Jo Valencia</td>\n",
       "      <td>0.44</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.62</td>\n",
       "      <td>17.13</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>10/20/17</td>\n",
       "      <td>10/20/17</td>\n",
       "      <td>APO AA 33776</td>\n",
       "      <td>179.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fffe3400380037003400</td>\n",
       "      <td>Wanda Warren</td>\n",
       "      <td>0.58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1210684.0</td>\n",
       "      <td>Marble</td>\n",
       "      <td>9703.37</td>\n",
       "      <td>35.42</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>02/22/16</td>\n",
       "      <td>02/24/16</td>\n",
       "      <td>South Kevin, VT 84493</td>\n",
       "      <td>627732.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fffe3200350036003700</td>\n",
       "      <td>Robert Ackies</td>\n",
       "      <td>0.97</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>Aluminium</td>\n",
       "      <td>40.21</td>\n",
       "      <td>18.54</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>01/11/18</td>\n",
       "      <td>01/10/18</td>\n",
       "      <td>Kevinshire, NE 31279</td>\n",
       "      <td>1565.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffe3800320034003400</td>\n",
       "      <td>Charlotte Membreno</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>Brass</td>\n",
       "      <td>4.55</td>\n",
       "      <td>17.48</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>08/06/16</td>\n",
       "      <td>08/06/16</td>\n",
       "      <td>DPO AP 61572</td>\n",
       "      <td>257.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fffe3600340033003000</td>\n",
       "      <td>Nena Silva</td>\n",
       "      <td>0.66</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marble</td>\n",
       "      <td>2726.80</td>\n",
       "      <td>30.23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Roadways</td>\n",
       "      <td>No</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/15/16</td>\n",
       "      <td>12/17/16</td>\n",
       "      <td>Joshuamouth, AK 01550</td>\n",
       "      <td>8553.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hospital_Id       Supplier_Name  Supplier_Reliability  \\\n",
       "0  fffe3200360030003700         Jo Valencia                  0.44   \n",
       "1  fffe3400380037003400        Wanda Warren                  0.58   \n",
       "2  fffe3200350036003700       Robert Ackies                  0.97   \n",
       "3  fffe3800320034003400  Charlotte Membreno                  0.70   \n",
       "4  fffe3600340033003000          Nena Silva                  0.66   \n",
       "\n",
       "   Equipment_Height  Equipment_Width  Equipment_Weight Equipment_Type  \\\n",
       "0              21.0              6.0               NaN            NaN   \n",
       "1              29.0             20.0         1210684.0         Marble   \n",
       "2              39.0             15.0            3305.0      Aluminium   \n",
       "3               8.0              5.0             606.0          Brass   \n",
       "4              27.0             13.0               NaN         Marble   \n",
       "\n",
       "   Equipment_Value  Base_Transport_Fee CrossBorder_Shipping Urgent_Shipping  \\\n",
       "0             3.62               17.13                   No              No   \n",
       "1          9703.37               35.42                   No             Yes   \n",
       "2            40.21               18.54                   No              No   \n",
       "3             4.55               17.48                   No              No   \n",
       "4          2726.80               30.23                  Yes              No   \n",
       "\n",
       "  Installation_Service Transport_Method Fragile_Equipment  Hospital_Info  \\\n",
       "0                   No         Roadways                No  Working Class   \n",
       "1                  Yes         Roadways                No  Working Class   \n",
       "2                   No         Roadways                No  Working Class   \n",
       "3                   No         Roadways                No  Working Class   \n",
       "4                   No         Roadways                No  Working Class   \n",
       "\n",
       "  Rural_Hospital Order_Placed_Date Delivery_Date      Hospital_Location  \\\n",
       "0             No          10/20/17      10/20/17           APO AA 33776   \n",
       "1             No          02/22/16      02/24/16  South Kevin, VT 84493   \n",
       "2             No          01/11/18      01/10/18   Kevinshire, NE 31279   \n",
       "3             No          08/06/16      08/06/16           DPO AP 61572   \n",
       "4            NaN          12/15/16      12/17/16  Joshuamouth, AK 01550   \n",
       "\n",
       "   Transport_Cost  \n",
       "0          179.50  \n",
       "1       627732.45  \n",
       "2         1565.92  \n",
       "3          257.71  \n",
       "4         8553.52  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (5000, 20)\n",
      "Cleaning string columns...\n",
      "Normalizing Yes/No columns...\n",
      "Converting date columns...\n",
      "Engineering Delivery_Days feature...\n",
      "Engineering more date features...\n",
      "Dropping duplicates...\n",
      "Dropped 0 duplicate rows.\n",
      "\n",
      "==============================\n",
      " CLEANING & FEATURE ENGINEERING COMPLETE \n",
      "==============================\n",
      "After basic cleaning shape: (5000, 24)\n",
      "\n",
      "Missing values (raw count):\n",
      "Hospital_Id                0\n",
      "Supplier_Name              0\n",
      "Supplier_Reliability     587\n",
      "Equipment_Height         283\n",
      "Equipment_Width          443\n",
      "Equipment_Weight         460\n",
      "Equipment_Type           599\n",
      "Equipment_Value            0\n",
      "Base_Transport_Fee         0\n",
      "CrossBorder_Shipping       0\n",
      "Urgent_Shipping            0\n",
      "Installation_Service       0\n",
      "Transport_Method        1071\n",
      "Fragile_Equipment          0\n",
      "Hospital_Info              0\n",
      "Rural_Hospital           586\n",
      "Order_Placed_Date          0\n",
      "Delivery_Date              0\n",
      "Hospital_Location          0\n",
      "Transport_Cost             0\n",
      "Delivery_Days              0\n",
      "Order_Month                0\n",
      "Order_Day_of_Week          0\n",
      "Order_Is_Weekend           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values (percentage):\n",
      "Transport_Method        21.42\n",
      "Equipment_Type          11.98\n",
      "Supplier_Reliability    11.74\n",
      "Rural_Hospital          11.72\n",
      "Equipment_Weight         9.20\n",
      "Equipment_Width          8.86\n",
      "Equipment_Height         5.66\n",
      "dtype: float64\n",
      "\n",
      "DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_Id</th>\n",
       "      <th>Supplier_Name</th>\n",
       "      <th>Supplier_Reliability</th>\n",
       "      <th>Equipment_Height</th>\n",
       "      <th>Equipment_Width</th>\n",
       "      <th>Equipment_Weight</th>\n",
       "      <th>Equipment_Type</th>\n",
       "      <th>Equipment_Value</th>\n",
       "      <th>Base_Transport_Fee</th>\n",
       "      <th>CrossBorder_Shipping</th>\n",
       "      <th>...</th>\n",
       "      <th>Hospital_Info</th>\n",
       "      <th>Rural_Hospital</th>\n",
       "      <th>Order_Placed_Date</th>\n",
       "      <th>Delivery_Date</th>\n",
       "      <th>Hospital_Location</th>\n",
       "      <th>Transport_Cost</th>\n",
       "      <th>Delivery_Days</th>\n",
       "      <th>Order_Month</th>\n",
       "      <th>Order_Day_of_Week</th>\n",
       "      <th>Order_Is_Weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fffe3200360030003700</td>\n",
       "      <td>Jo Valencia</td>\n",
       "      <td>0.44</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.62</td>\n",
       "      <td>17.13</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>APO AA 33776</td>\n",
       "      <td>179.50</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fffe3400380037003400</td>\n",
       "      <td>Wanda Warren</td>\n",
       "      <td>0.58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1210684.0</td>\n",
       "      <td>Marble</td>\n",
       "      <td>9703.37</td>\n",
       "      <td>35.42</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>2016-02-22</td>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>South Kevin, VT 84493</td>\n",
       "      <td>627732.45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fffe3200350036003700</td>\n",
       "      <td>Robert Ackies</td>\n",
       "      <td>0.97</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>Aluminium</td>\n",
       "      <td>40.21</td>\n",
       "      <td>18.54</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Kevinshire, NE 31279</td>\n",
       "      <td>1565.92</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffe3800320034003400</td>\n",
       "      <td>Charlotte Membreno</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>Brass</td>\n",
       "      <td>4.55</td>\n",
       "      <td>17.48</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>No</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>DPO AP 61572</td>\n",
       "      <td>257.71</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fffe3600340033003000</td>\n",
       "      <td>Nena Silva</td>\n",
       "      <td>0.66</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marble</td>\n",
       "      <td>2726.80</td>\n",
       "      <td>30.23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Working Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>Joshuamouth, AK 01550</td>\n",
       "      <td>8553.52</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hospital_Id       Supplier_Name  Supplier_Reliability  \\\n",
       "0  fffe3200360030003700         Jo Valencia                  0.44   \n",
       "1  fffe3400380037003400        Wanda Warren                  0.58   \n",
       "2  fffe3200350036003700       Robert Ackies                  0.97   \n",
       "3  fffe3800320034003400  Charlotte Membreno                  0.70   \n",
       "4  fffe3600340033003000          Nena Silva                  0.66   \n",
       "\n",
       "   Equipment_Height  Equipment_Width  Equipment_Weight Equipment_Type  \\\n",
       "0              21.0              6.0               NaN            NaN   \n",
       "1              29.0             20.0         1210684.0         Marble   \n",
       "2              39.0             15.0            3305.0      Aluminium   \n",
       "3               8.0              5.0             606.0          Brass   \n",
       "4              27.0             13.0               NaN         Marble   \n",
       "\n",
       "   Equipment_Value  Base_Transport_Fee CrossBorder_Shipping  ...  \\\n",
       "0             3.62               17.13                   No  ...   \n",
       "1          9703.37               35.42                   No  ...   \n",
       "2            40.21               18.54                   No  ...   \n",
       "3             4.55               17.48                   No  ...   \n",
       "4          2726.80               30.23                  Yes  ...   \n",
       "\n",
       "   Hospital_Info Rural_Hospital Order_Placed_Date Delivery_Date  \\\n",
       "0  Working Class             No        2017-10-20    2017-10-20   \n",
       "1  Working Class             No        2016-02-22    2016-02-24   \n",
       "2  Working Class             No        2018-01-11    2018-01-10   \n",
       "3  Working Class             No        2016-08-06    2016-08-06   \n",
       "4  Working Class            NaN        2016-12-15    2016-12-17   \n",
       "\n",
       "       Hospital_Location Transport_Cost Delivery_Days Order_Month  \\\n",
       "0           APO AA 33776         179.50             0          10   \n",
       "1  South Kevin, VT 84493      627732.45             2           2   \n",
       "2   Kevinshire, NE 31279        1565.92            -1           1   \n",
       "3           DPO AP 61572         257.71             0           8   \n",
       "4  Joshuamouth, AK 01550        8553.52             2          12   \n",
       "\n",
       "  Order_Day_of_Week  Order_Is_Weekend  \n",
       "0                 4             False  \n",
       "1                 0             False  \n",
       "2                 3             False  \n",
       "3                 5              True  \n",
       "4                 3             False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "# 1️⃣ Load Data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "display(df.head())\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "\n",
    "# 2️⃣ Clean all string/object columns: strip spaces, replace blanks with NaN\n",
    "print(\"Cleaning string columns...\")\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].replace({'': np.nan, 'nan': np.nan, 'NaN': np.nan})\n",
    "\n",
    "# 3️⃣ Normalize Yes/No columns to consistent \"Yes\"/\"No\"\n",
    "print(\"Normalizing Yes/No columns...\")\n",
    "yes_no_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',\n",
    "               'Fragile_Equipment', 'Rural_Hospital']\n",
    "for col in yes_no_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace({\n",
    "            'YES': 'Yes', 'yes': 'Yes', 'Y': 'Yes', 'y': 'Yes',\n",
    "            'NO': 'No', 'no': 'No', 'N': 'No', 'n': 'No'\n",
    "        })\n",
    "\n",
    "# 4️⃣ Convert date columns to datetime\n",
    "print(\"Converting date columns...\")\n",
    "df['Order_Placed_Date'] = pd.to_datetime(df['Order_Placed_Date'], errors='coerce')\n",
    "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
    "\n",
    "# 5️⃣ Create new feature: Delivery_Days (difference in days)\n",
    "print(\"Engineering Delivery_Days feature...\")\n",
    "df['Delivery_Days'] = (df['Delivery_Date'] - df['Order_Placed_Date']).dt.days\n",
    "df['Delivery_Days'] = pd.to_numeric(df['Delivery_Days'], errors='coerce')\n",
    "\n",
    "# === ADDED: Date Feature Engineering ===\n",
    "print(\"Engineering more date features...\")\n",
    "df['Order_Month'] = df['Order_Placed_Date'].dt.month\n",
    "df['Order_Day_of_Week'] = df['Order_Placed_Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['Order_Is_Weekend'] = df['Order_Day_of_Week'].isin([5, 6])\n",
    "# === END ADDED ===\n",
    "\n",
    "# 6️⃣ (Original) delete initial date rows\n",
    "# df = df.dropna(subset=['Order_Placed_Date', 'Delivery_Date'])\n",
    "\n",
    "# 7️⃣ Drop exact duplicate rows\n",
    "print(\"Dropping duplicates...\")\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} duplicate rows.\")\n",
    "\n",
    "# 8️⃣ Quick check after cleaning\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\" CLEANING & FEATURE ENGINEERING COMPLETE \")\n",
    "print(\"=\"*30)\n",
    "print(f\"After basic cleaning shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nMissing values (raw count):\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# === ADDED: Missing Value Percentage View ===\n",
    "print(\"\\nMissing values (percentage):\")\n",
    "missing_pct = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "print(missing_pct[missing_pct > 0])\n",
    "# === END ADDED ===\n",
    "\n",
    "print(\"\\nDataFrame head:\")\n",
    "display(df.head())\n",
    "# print(df['Delivery_Days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c51803e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing script started...\n",
      "5000\n",
      "Filtered 493 rows with negative cost.\n",
      "Created 'Is_Negative_Delivery' flag.\n",
      "Log-transformed skewed numeric features.\n",
      "Applied log1p to target variable 'Transport_Cost'.\n",
      "Total features for modeling: 18\n",
      "\n",
      "Calculating baseline...\n",
      "Baseline RMSE (predicting mean cost): $143,852.70\n",
      "Training set shape: (3605, 18)\n",
      "Test set shape: (902, 18)\n",
      "\n",
      "Fitting preprocessor on X_train...\n",
      "Preprocessing complete.\n",
      "Processed X_train shape: (3605, 51)\n",
      "Processed X_test shape: (902, 51)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Preprocessing script started...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 1: PRE-SPLIT (Final Cleaning & Feature Engineering)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Filter Bad Data\n",
    "initial_rows = len(df)\n",
    "print(initial_rows)\n",
    "df = df[df['Transport_Cost'] >= 0]\n",
    "print(f\"Filtered {initial_rows - len(df)} rows with negative cost.\")\n",
    "\n",
    "# 2. Equipment Feature Engineering\n",
    "df['Equipment_Volume'] = df['Equipment_Height'] * df['Equipment_Width']\n",
    "\n",
    "# 3. Delivery_Days Feature Engineering (THE FIX)\n",
    "# (!!! THIS IS THE FIX !!!)\n",
    "# Create the flag column *before* modifying Delivery_Days\n",
    "df['Is_Negative_Delivery'] = (df['Delivery_Days'] < 0).astype(int) \n",
    "print(\"Created 'Is_Negative_Delivery' flag.\")\n",
    "\n",
    "# Now, modify Delivery_Days (your suggestion)\n",
    "df['Delivery_Days'] = np.where(df['Delivery_Days'] < 0, -1, df['Delivery_Days'])\n",
    "# print(\"Set negative Delivery_Days to -1.\")\n",
    "# no change to Delivery_Days as per latest discussion\n",
    "\n",
    "# 4. Log-Transform Skewed *Features*\n",
    "df['Equipment_Value'] = np.log1p(df['Equipment_Value'])\n",
    "df['Equipment_Volume'] = np.log1p(df['Equipment_Volume'])\n",
    "df['Equipment_Weight'] = np.log1p(df['Equipment_Weight'])\n",
    "df['Base_Transport_Fee'] = np.log1p(df['Base_Transport_Fee'])\n",
    "print(\"Log-transformed skewed numeric features.\")\n",
    "\n",
    "# 5. Define Target (y) and Features (X)\n",
    "y_original = df['Transport_Cost'] # Keep original for baseline\n",
    "y = np.log1p(y_original)         # This is the target we will train on\n",
    "print(\"Applied log1p to target variable 'Transport_Cost'.\")\n",
    "\n",
    "# Define X by dropping the target and all redundant/ID/replaced columns.\n",
    "X = df.drop(columns=[\n",
    "    'Transport_Cost',       # Target\n",
    "    'Equipment_Height',     # Replaced by Volume\n",
    "    'Equipment_Width',      # Replaced by Volume\n",
    "    'Hospital_Id',          # ID\n",
    "    'Supplier_Name',        # ID\n",
    "    'Hospital_Location',    # ID\n",
    "    'Order_Placed_Date',    # Replaced by date features\n",
    "    'Delivery_Date'         # Replaced by date features\n",
    "])\n",
    "\n",
    "print(f\"Total features for modeling: {len(X.columns)}\")\n",
    "\n",
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Calculate Baseline RMSE (in DOLLARS)\n",
    "print(\"\\nCalculating baseline...\")\n",
    "y_train_original_mean = y_original.loc[y_train.index].mean()\n",
    "y_test_original = y_original.loc[y_test.index]\n",
    "\n",
    "y_test_pred_baseline = np.full_like(y_test_original, y_train_original_mean)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test_original, y_test_pred_baseline))\n",
    "print(f\"Baseline RMSE (predicting mean cost): ${baseline_rmse:,.2f}\")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: POST-SPLIT (Pipelines & ColumnTransformer)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define Feature Lists\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability',\n",
    "    'Equipment_Value',      # Log-transformed\n",
    "    'Base_Transport_Fee',   # Log-transformed\n",
    "    'Delivery_Days',        # Clipped at -1\n",
    "    'Equipment_Volume',     # Log-transformed\n",
    "    'Equipment_Weight'      # Log-transformed\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Equipment_Type',\n",
    "    'CrossBorder_Shipping',\n",
    "    'Urgent_Shipping',\n",
    "    'Installation_Service',\n",
    "    'Transport_Method',\n",
    "    'Fragile_Equipment',\n",
    "    'Hospital_Info',\n",
    "    'Rural_Hospital',\n",
    "    'Order_Month',\n",
    "    'Order_Day_of_Week',\n",
    "    'Order_Is_Weekend',\n",
    "    'Is_Negative_Delivery'  # <-- This column now exists\n",
    "]\n",
    "\n",
    "# 2. Create the Numeric Pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# 3. Create the Categorical Pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 4. Create the Full Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# 5. Apply the Preprocessor\n",
    "print(\"\\nFitting preprocessor on X_train...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test) \n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(f\"Processed X_train shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed X_test shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ac567db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ..............poly__degree=1, regressor__alpha=0.01; total time=   0.0s\n",
      "[CV] END ..............poly__degree=1, regressor__alpha=0.01; total time=   0.0s\n",
      "[CV] END ..............poly__degree=1, regressor__alpha=0.01; total time=   0.0s\n",
      "[CV] END ..............poly__degree=1, regressor__alpha=0.01; total time=   0.0s\n",
      "[CV] END ...............poly__degree=1, regressor__alpha=0.1; total time=   0.0s\n",
      "[CV] END ..............poly__degree=1, regressor__alpha=0.01; total time=   0.0s\n",
      "[CV] END ...............poly__degree=1, regressor__alpha=0.1; total time=   0.0s\n",
      "[CV] END ...............poly__degree=1, regressor__alpha=0.1; total time=   0.0s\n",
      "[CV] END ...............poly__degree=1, regressor__alpha=0.1; total time=   0.0s\n",
      "[CV] END ...............poly__degree=1, regressor__alpha=0.1; total time=   0.0s\n",
      "[CV] END .................poly__degree=1, regressor__alpha=1; total time=   0.0s\n",
      "[CV] END .................poly__degree=1, regressor__alpha=1; total time=   0.0s\n",
      "[CV] END .................poly__degree=1, regressor__alpha=1; total time=   0.0s\n",
      "[CV] END .................poly__degree=1, regressor__alpha=1; total time=   0.0s\n",
      "[CV] END ................poly__degree=1, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END .................poly__degree=1, regressor__alpha=1; total time=   0.0s\n",
      "[CV] END ................poly__degree=1, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END ................poly__degree=1, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END ................poly__degree=1, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END ................poly__degree=1, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END .................poly__degree=2, regressor__alpha=1; total time=   0.1s\n",
      "[CV] END .................poly__degree=2, regressor__alpha=1; total time=   0.1s\n",
      "[CV] END .................poly__degree=2, regressor__alpha=1; total time=   0.1s\n",
      "[CV] END ...............poly__degree=2, regressor__alpha=0.1; total time=   0.2s\n",
      "[CV] END ...............poly__degree=2, regressor__alpha=0.1; total time=   0.2s\n",
      "[CV] END ...............poly__degree=2, regressor__alpha=0.1; total time=   0.2s\n",
      "[CV] END .................poly__degree=2, regressor__alpha=1; total time=   0.1s\n",
      "[CV] END ...............poly__degree=2, regressor__alpha=0.1; total time=   0.2s\n",
      "[CV] END ...............poly__degree=2, regressor__alpha=0.1; total time=   0.2s\n",
      "[CV] END ..............poly__degree=2, regressor__alpha=0.01; total time=   0.3s\n",
      "[CV] END ..............poly__degree=2, regressor__alpha=0.01; total time=   0.3s\n",
      "[CV] END ................poly__degree=2, regressor__alpha=10; total time=   0.0s\n",
      "[CV] END ................poly__degree=2, regressor__alpha=10; total time=   0.1s\n",
      "[CV] END ..............poly__degree=2, regressor__alpha=0.01; total time=   0.3s\n",
      "[CV] END ................poly__degree=2, regressor__alpha=10; total time=   0.1s\n",
      "[CV] END .................poly__degree=2, regressor__alpha=1; total time=   0.1s\n",
      "[CV] END ................poly__degree=2, regressor__alpha=10; total time=   0.1s\n",
      "[CV] END ..............poly__degree=2, regressor__alpha=0.01; total time=   0.3s\n",
      "[CV] END ................poly__degree=2, regressor__alpha=10; total time=   0.1s\n",
      "[CV] END ..............poly__degree=2, regressor__alpha=0.01; total time=   0.3s\n",
      "Best parameters: {'poly__degree': 2, 'regressor__alpha': 0.01}\n",
      "Best CV RMSE: 0.4467\n",
      "Test RMSE: 0.4524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier_Reliability</td>\n",
       "      <td>0.658071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base_Transport_Fee</td>\n",
       "      <td>0.490455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Equipment_Value^2</td>\n",
       "      <td>0.415364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Equipment_Value Urgent_Shipping_Yes</td>\n",
       "      <td>0.284314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Equipment_Value</td>\n",
       "      <td>0.282179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Equipment_Weight</td>\n",
       "      <td>0.271746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Supplier_Reliability Equipment_Volume</td>\n",
       "      <td>0.128342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Base_Transport_Fee Urgent_Shipping_No</td>\n",
       "      <td>0.119615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Equipment_Volume</td>\n",
       "      <td>0.111701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Base_Transport_Fee Equipment_Weight</td>\n",
       "      <td>-0.067655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Supplier_Reliability^2</td>\n",
       "      <td>0.062623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Equipment_Value Equipment_Volume</td>\n",
       "      <td>0.061221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Equipment_Value Transport_Method_Airways</td>\n",
       "      <td>0.061193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delivery_Days</td>\n",
       "      <td>-0.053651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Urgent_Shipping_Yes Installation_Service_Yes</td>\n",
       "      <td>0.047324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Urgent_Shipping_No Rural_Hospital_No</td>\n",
       "      <td>-0.034831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Supplier_Reliability Base_Transport_Fee</td>\n",
       "      <td>0.032771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>CrossBorder_Shipping_No Hospital_Info_Working ...</td>\n",
       "      <td>-0.031963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Equipment_Value Base_Transport_Fee</td>\n",
       "      <td>-0.031143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Installation_Service_No Is_Negative_Delivery_0</td>\n",
       "      <td>-0.027375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Fragile_Equipment_No Hospital_Info_Working Class</td>\n",
       "      <td>-0.025689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Installation_Service_No Fragile_Equipment_No</td>\n",
       "      <td>-0.023155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Installation_Service_No Rural_Hospital_No</td>\n",
       "      <td>-0.022769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Urgent_Shipping_No Is_Negative_Delivery_0</td>\n",
       "      <td>-0.021859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Equipment_Value Equipment_Type_Aluminium</td>\n",
       "      <td>0.021606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Equipment_Value CrossBorder_Shipping_Yes</td>\n",
       "      <td>0.017531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Equipment_Volume^2</td>\n",
       "      <td>0.015623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Transport_Method_Airways</td>\n",
       "      <td>0.011663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Installation_Service_No Order_Is_Weekend_False</td>\n",
       "      <td>-0.008325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Transport_Method_Waterways</td>\n",
       "      <td>-0.007197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature  coefficient\n",
       "1                                 Supplier_Reliability     0.658071\n",
       "3                                   Base_Transport_Fee     0.490455\n",
       "103                                  Equipment_Value^2     0.415364\n",
       "118                Equipment_Value Urgent_Shipping_Yes     0.284314\n",
       "2                                      Equipment_Value     0.282179\n",
       "6                                     Equipment_Weight     0.271746\n",
       "56               Supplier_Reliability Equipment_Volume     0.128342\n",
       "166              Base_Transport_Fee Urgent_Shipping_No     0.119615\n",
       "5                                     Equipment_Volume     0.111701\n",
       "156                Base_Transport_Fee Equipment_Weight    -0.067655\n",
       "52                              Supplier_Reliability^2     0.062623\n",
       "106                   Equipment_Value Equipment_Volume     0.061221\n",
       "121           Equipment_Value Transport_Method_Airways     0.061193\n",
       "4                                        Delivery_Days    -0.053651\n",
       "750       Urgent_Shipping_Yes Installation_Service_Yes     0.047324\n",
       "723               Urgent_Shipping_No Rural_Hospital_No    -0.034831\n",
       "54             Supplier_Reliability Base_Transport_Fee     0.032771\n",
       "649  CrossBorder_Shipping_No Hospital_Info_Working ...    -0.031963\n",
       "104                 Equipment_Value Base_Transport_Fee    -0.031143\n",
       "815     Installation_Service_No Is_Negative_Delivery_0    -0.027375\n",
       "946   Fragile_Equipment_No Hospital_Info_Working Class    -0.025689\n",
       "788       Installation_Service_No Fragile_Equipment_No    -0.023155\n",
       "792          Installation_Service_No Rural_Hospital_No    -0.022769\n",
       "746          Urgent_Shipping_No Is_Negative_Delivery_0    -0.021859\n",
       "108           Equipment_Value Equipment_Type_Aluminium     0.021606\n",
       "116           Equipment_Value CrossBorder_Shipping_Yes     0.017531\n",
       "250                                 Equipment_Volume^2     0.015623\n",
       "20                            Transport_Method_Airways     0.011663\n",
       "813     Installation_Service_No Order_Is_Weekend_False    -0.008325\n",
       "22                          Transport_Method_Waterways    -0.007197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1️⃣ Create full pipeline\n",
    "# ==============================\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),        # handle numeric + categorical\n",
    "    ('poly', PolynomialFeatures()),        # now safe\n",
    "    ('regressor', Lasso(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# ==============================\n",
    "# 2️⃣ Define hyperparameter grid\n",
    "# ==============================\n",
    "param_grid = {\n",
    "    'poly__degree': [1,2],             # polynomial degree\n",
    "    'regressor__alpha': [0.01, 0.1, 1, 10]  # Lasso regularization\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 3️⃣ Setup GridSearchCV with K-Fold\n",
    "# ==============================\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=kf,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 4️⃣ Fit GridSearch on training data\n",
    "# ==============================\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ==============================\n",
    "# 5️⃣ Best parameters and CV RMSE\n",
    "# ==============================\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(f\"Best CV RMSE: {best_rmse:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# 6️⃣ Evaluate on test set\n",
    "# ==============================\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# 7️⃣ Feature importance: Top 30 by absolute coefficient\n",
    "# ==============================\n",
    "best_model = grid_search.best_estimator_.named_steps['regressor']\n",
    "preprocessor = grid_search.best_estimator_.named_steps['preprocessor']\n",
    "poly = grid_search.best_estimator_.named_steps['poly']\n",
    "\n",
    "# numeric + categorical feature names\n",
    "num_features = numeric_features\n",
    "cat_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "all_features = np.concatenate([num_features, cat_features])\n",
    "\n",
    "# polynomial feature names\n",
    "poly_feature_names = poly.get_feature_names_out(all_features)\n",
    "\n",
    "# match coefficients to feature names\n",
    "coef = best_model.coef_\n",
    "feature_coef_df = pd.DataFrame({\n",
    "    'feature': poly_feature_names,\n",
    "    'coefficient': coef\n",
    "})\n",
    "\n",
    "# Top 30 features by absolute value\n",
    "top_30 = feature_coef_df.reindex(feature_coef_df['coefficient'].abs().sort_values(ascending=False).index).head(30)\n",
    "display(top_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2eb96fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting V6 GridSearchCV for XGBoost (Focusing on EXTREME ROBUSTNESS)...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1000, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.1s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=10, xgb__reg_lambda=100; total time=   0.3s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=50, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=10; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=50; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "[CV] END xgb__max_depth=3, xgb__n_estimators=1500, xgb__reg_alpha=100, xgb__reg_lambda=100; total time=   0.2s\n",
      "\n",
      "✅ V6 GridSearch complete!\n",
      "   Best hyperparameters: {'xgb__max_depth': 3, 'xgb__n_estimators': 1000, 'xgb__reg_alpha': 10, 'xgb__reg_lambda': 50}\n",
      "   Best CV RMSE (log-space): 0.3738\n",
      "\n",
      "   Test RMSE (log-space)      : 0.3516\n",
      "   Test RMSE (original scale) : 113487.74\n"
     ]
    }
   ],
   "source": [
    "# === CELL 4 (V6): GRIDSEARCHCV FOR EXTREME ROBUSTNESS ===\n",
    "\n",
    "print(\"🚀 Starting V6 GridSearchCV for XGBoost (Focusing on EXTREME ROBUSTNESS)...\")\n",
    "\n",
    "# --- 1. CV splitter ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 2. XGB pipeline ---\n",
    "# 'preprocessor' is your V4 preprocessor (with RobustScaler)\n",
    "# This MUST be the V4 preprocessor object, already in your memory\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('xgb', XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        learning_rate=0.05 # Slower learning rate for more stability\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- 3. V6 Hyperparameter grid (Shallow, Regularized) ---\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [1000, 1500],\n",
    "    'xgb__max_depth': [3],               # Force shallow trees\n",
    "    'xgb__reg_alpha': [10, 50, 100],     # Aggressive L1\n",
    "    'xgb__reg_lambda': [10, 50, 100]     # Aggressive L2\n",
    "}\n",
    "\n",
    "# --- 4. GridSearchCV ---\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- 5. Run grid search on the V4 TRAINING DATA ---\n",
    "# (X_train and y_train are from your V4 preprocessing cell)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Best params & CV score ---\n",
    "print(\"\\n✅ V6 GridSearch complete!\")\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_rmse = -grid_search.best_score_\n",
    "print(f\"   Best hyperparameters: {best_params}\")\n",
    "print(f\"   Best CV RMSE (log-space): {best_cv_rmse:.4f}\")\n",
    "\n",
    "# --- 7. Evaluate on V4 test set ---\n",
    "final_xgb_bulletproof_v6 = grid_search.best_estimator_\n",
    "y_test_pred_log = final_xgb_bulletproof_v6.predict(X_test)\n",
    "y_test_pred_orig = np.expm1(y_test_pred_log)\n",
    "\n",
    "rmse_test_log = np.sqrt(mean_squared_error(y_test, y_test_pred_log))\n",
    "rmse_test_orig = np.sqrt(mean_squared_error(np.expm1(y_test), y_test_pred_orig))\n",
    "\n",
    "print(f\"\\n   Test RMSE (log-space)      : {rmse_test_log:.4f}\")\n",
    "print(f\"   Test RMSE (original scale) : {rmse_test_orig:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Starting GridSearchCV for Polynomial Ridge...\")\n",
    "\n",
    "# --- 1. CV splitter ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 2. Polynomial Ridge pipeline ---\n",
    "# We are adding a new step: 'poly'\n",
    "# The pipeline is now: Preprocessor -> PolynomialFeatures -> Ridge\n",
    "poly_ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('poly', PolynomialFeatures(include_bias=False)), # <-- NEW STEP\n",
    "    ('ridge', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "# --- 3. Hyperparameter grid ---\n",
    "# We now tune both the polynomial degree and the ridge alpha\n",
    "param_grid = {\n",
    "    'poly__degree': [1], # Degree 1 = linear (your old model), Degree 2 = quadratic\n",
    "    'ridge__alpha': [1, 10, 20,50, 100] # Test a wide range of L2 regularization\n",
    "}\n",
    "\n",
    "# --- 4. GridSearchCV ---\n",
    "# Using a new variable name 'grid_search_poly'\n",
    "grid_search_poly = GridSearchCV(\n",
    "    estimator=poly_ridge_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- 5. Run grid search ---\n",
    "# We fit on the raw X_train and y_train\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Best params & CV score ---\n",
    "print(\"\\n✅ Polynomial Ridge GridSearch complete!\")\n",
    "best_params_poly = grid_search_poly.best_params_\n",
    "best_cv_rmse_poly = -grid_search_poly.best_score_\n",
    "print(f\"   Best hyperparameters: {best_params_poly}\")\n",
    "print(f\"   Best CV RMSE (log-space): {best_cv_rmse_poly:.4f}\")\n",
    "\n",
    "# --- 7. Evaluate on V4 test set ---\n",
    "final_poly_ridge = grid_search_poly.best_estimator_\n",
    "y_test_pred_log_poly = final_poly_ridge.predict(X_test)\n",
    "y_test_pred_orig_poly = np.expm1(y_test_pred_log_poly)\n",
    "\n",
    "# (Safety check: set any potential negative predictions to 0)\n",
    "y_test_pred_orig_poly[y_test_pred_orig_poly < 0] = 0\n",
    "\n",
    "# We use the original y_test_original from your baseline cell\n",
    "rmse_test_log_poly = np.sqrt(mean_squared_error(y_test, y_test_pred_log_poly))\n",
    "rmse_test_orig_poly = np.sqrt(mean_squared_error(y_test_original, y_test_pred_orig_poly))\n",
    "\n",
    "print(f\"\\n   Test RMSE (log-space)      : {rmse_test_log_poly:.4f}\")\n",
    "print(f\"   Test RMSE (original scale) : ${rmse_test_orig_poly:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Retraining final Polynomial Ridge model on ALL available data...\")\n",
    "\n",
    "# === 1. Get Best Hyperparameters (DYNAMICALLY) ===\n",
    "try:\n",
    "    # Get the best params from the 'grid_search_poly' object\n",
    "    best_params_poly = grid_search_poly.best_params_\n",
    "    best_degree = best_params_poly['poly__degree']\n",
    "    best_alpha = best_params_poly['ridge__alpha']\n",
    "    print(f\"   Using best hyperparameters: {best_params_poly}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(\"\\nERROR: Could not run. 'grid_search_poly' not found.\")\n",
    "    print(\"Please make sure you have run the 'Polynomial Ridge GridSearchCV' cell successfully first.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    # We'll stop the script if the params aren't found\n",
    "    raise\n",
    "\n",
    "# === 2. Re-define the Preprocessor (for clarity and safety) ===\n",
    "# This is the exact same preprocessor from your \"V4\" script\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability', 'Equipment_Value', 'Base_Transport_Fee',\n",
    "    'Delivery_Days', 'Equipment_Volume', 'Equipment_Weight'\n",
    "]\n",
    "categorical_features = [\n",
    "    'Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping',\n",
    "    'Installation_Service', 'Transport_Method', 'Fragile_Equipment',\n",
    "    'Hospital_Info', 'Rural_Hospital', 'Order_Month',\n",
    "    'Order_Day_of_Week', 'Order_Is_Weekend', 'Is_Negative_Delivery'\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "final_preprocessor_poly = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# === 3. Build the Final Model and Pipeline ===\n",
    "# Create the final pipeline with the 'poly' step and best params\n",
    "final_model_pipeline_poly = Pipeline(steps=[\n",
    "    ('preprocessor', final_preprocessor_poly),\n",
    "    ('poly', PolynomialFeatures(degree=best_degree, include_bias=False)), # <-- Uses best_degree\n",
    "    ('model', Ridge(alpha=best_alpha, random_state=42))                   # <-- Uses best_alpha\n",
    "])\n",
    "\n",
    "# === 4. Fit on the ENTIRE dataset ===\n",
    "# We use 'X' and 'y' (the full, pre-split data)\n",
    "print(f\"\\nFitting pipeline on {X.shape[0]} rows of data...\")\n",
    "final_model_pipeline_poly.fit(X, y)\n",
    "\n",
    "print(\"\\n✅ Final Polynomial Ridge model trained on entire dataset!\")\n",
    "print(\"You can now use this 'final_model_pipeline_poly' for all predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d17b8448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Retraining final model on ALL available data...\n",
      "   Using best hyperparameters: {'max_depth': 3, 'n_estimators': 1000, 'reg_alpha': 10, 'reg_lambda': 50}\n",
      "\n",
      "Fitting pipeline on 4507 rows of data...\n",
      "\n",
      "✅ Final XGBoost model trained on entire dataset!\n",
      "You can now use this 'final_model_pipeline' for all predictions.\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Retraining final model on ALL available data...\")\n",
    "\n",
    "# === 1. Get Best Hyperparameters ===\n",
    "# Get the best params found by GridSearchCV (V6)\n",
    "# The keys will be like 'xgb__n_estimators', we need to clean them\n",
    "best_params_raw = grid_search.best_params_\n",
    "best_params = {key.replace('xgb__', ''): value for key, value in best_params_raw.items()}\n",
    "\n",
    "print(f\"   Using best hyperparameters: {best_params}\")\n",
    "\n",
    "# === 2. Re-define the Preprocessor (for clarity and safety) ===\n",
    "# This is the exact same preprocessor from your \"V4\" script\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability', 'Equipment_Value', 'Base_Transport_Fee',\n",
    "    'Delivery_Days', 'Equipment_Volume', 'Equipment_Weight'\n",
    "]\n",
    "categorical_features = [\n",
    "    'Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping',\n",
    "    'Installation_Service', 'Transport_Method', 'Fragile_Equipment',\n",
    "    'Hospital_Info', 'Rural_Hospital', 'Order_Month',\n",
    "    'Order_Day_of_Week', 'Order_Is_Weekend', 'Is_Negative_Delivery'\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# === 3. Build the Final Model and Pipeline ===\n",
    "# Create a new XGBoost model instance with the best params\n",
    "final_xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    learning_rate=0.05, # This was fixed in your grid search\n",
    "    **best_params       # This unpacks all the best params (n_estimators, max_depth, etc.)\n",
    ")\n",
    "\n",
    "# Create the final pipeline\n",
    "final_model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', final_preprocessor),\n",
    "    ('model', final_xgb_model)\n",
    "])\n",
    "\n",
    "# === 4. Fit on the ENTIRE dataset ===\n",
    "# We use 'X' and 'y' (the full, pre-split data)\n",
    "print(f\"\\nFitting pipeline on {X.shape[0]} rows of data...\")\n",
    "final_model_pipeline.fit(X, y)\n",
    "\n",
    "print(\"\\n✅ Final XGBoost model trained on entire dataset!\")\n",
    "print(\"You can now use this 'final_model_pipeline' for all predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a6d099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df_raw):\n",
    "    \"\"\"\n",
    "    Applies all manual cleaning and feature engineering\n",
    "    to match the data used for model training.\n",
    "    \n",
    "    Takes a raw DataFrame (like test.csv) and returns\n",
    "    a DataFrame ready for the preprocessor pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Preparing {len(df_raw)} new rows...\")\n",
    "    \n",
    "    # Make a copy to avoid changing the original data\n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # 1. Clean column names (from your training script)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # 2. Clean all string/object columns (from your training script)\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df[col] = df[col].replace({'': np.nan, 'nan': np.nan, 'NaN': np.nan})\n",
    "\n",
    "    # 3. Normalize Yes/No columns (from your training script)\n",
    "    yes_no_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',\n",
    "                   'Fragile_Equipment', 'Rural_Hospital']\n",
    "    for col in yes_no_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace({\n",
    "                'YES': 'Yes', 'yes': 'Yes', 'Y': 'Yes', 'y': 'Yes',\n",
    "                'NO': 'No', 'no': 'No', 'N': 'No', 'n': 'No'\n",
    "            })\n",
    "\n",
    "    # 4. Convert date columns (from your training script)\n",
    "    df['Order_Placed_Date'] = pd.to_datetime(df['Order_Placed_Date'], errors='coerce')\n",
    "    df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
    "\n",
    "    # 5. Engineer Date Features (from your training script)\n",
    "    df['Delivery_Days'] = (df['Delivery_Date'] - df['Order_Placed_Date']).dt.days\n",
    "    df['Delivery_Days'] = pd.to_numeric(df['Delivery_Days'], errors='coerce')\n",
    "    \n",
    "    df['Order_Month'] = df['Order_Placed_Date'].dt.month.astype(str)\n",
    "    df['Order_Day_of_Week'] = df['Order_Placed_Date'].dt.dayofweek.astype(str)\n",
    "    df['Order_Is_Weekend'] = (df['Order_Placed_Date'].dt.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    # 6. Engineer Equipment_Volume (from your training script)\n",
    "    df['Equipment_Volume'] = df['Equipment_Height'] * df['Equipment_Width']\n",
    "    \n",
    "    # 7. Engineer Delivery_Days features (from your training script)\n",
    "    # This *must* be in this order\n",
    "    df['Is_Negative_Delivery'] = (df['Delivery_Days'] < 0).astype(int)\n",
    "    df['Delivery_Days'] = np.where(df['Delivery_Days'] < 0, -1, df['Delivery_Days'])\n",
    "\n",
    "    # 8. Log-Transform Skewed Features (from your training script)\n",
    "    df['Equipment_Value'] = np.log1p(df['Equipment_Value'])\n",
    "    df['Equipment_Volume'] = np.log1p(df['Equipment_Volume'])\n",
    "    df['Equipment_Weight'] = np.log1p(df['Equipment_Weight'])\n",
    "    df['Base_Transport_Fee'] = np.log1p(df['Base_Transport_Fee'])\n",
    "    \n",
    "    print(\"Feature preparation complete.\")\n",
    "    \n",
    "    # 9. Return the feature-engineered DataFrame\n",
    "    # The preprocessor pipeline will select the columns it needs from this.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1267db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading new test data...\n",
      "Applying feature engineering to new data...\n",
      "Preparing 500 new rows...\n",
      "Feature preparation complete.\n",
      "Getting predictions from the final model...\n",
      "\n",
      "Final Predictions (in $):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_Id</th>\n",
       "      <th>Transport_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fffe33003400</td>\n",
       "      <td>450.034637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fffe3700330036003600</td>\n",
       "      <td>284.725525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fffe3300390038003400</td>\n",
       "      <td>2074.483643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffe310030003900</td>\n",
       "      <td>211.848755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fffe3700330031003200</td>\n",
       "      <td>1021.790283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hospital_Id  Transport_Cost\n",
       "0          fffe33003400      450.034637\n",
       "1  fffe3700330036003600      284.725525\n",
       "2  fffe3300390038003400     2074.483643\n",
       "3      fffe310030003900      211.848755\n",
       "4  fffe3700330031003200     1021.790283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'xgb.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assume 'final_model_pipeline' and 'prepare_features' are in memory\n",
    "# If not, you would load your model:\n",
    "# import joblib\n",
    "# final_model_pipeline = joblib.load('final_xgb_model.pkl') \n",
    "\n",
    "# 1. Load your new, raw test data\n",
    "print(\"Loading new test data...\")\n",
    "df_new_test = pd.read_csv('../data/test.csv') \n",
    "\n",
    "# 2. Save IDs for the final submission\n",
    "# We need to map our predictions back to the original IDs\n",
    "submission_ids = df_new_test['Hospital_Id']\n",
    "\n",
    "# 3. Apply the *exact same* feature engineering\n",
    "print(\"Applying feature engineering to new data...\")\n",
    "X_new_prepared = prepare_features(df_new_test)\n",
    "\n",
    "# 4. Get predictions\n",
    "print(\"Getting predictions from the final model...\")\n",
    "log_predictions = final_model_pipeline.predict(X_new_prepared)\n",
    "\n",
    "# 5. Convert predictions back from log-scale! (THE FIX)\n",
    "# Remember, you trained on log(Transport_Cost + 1)\n",
    "final_predictions = np.expm1(log_predictions)\n",
    "\n",
    "# (Safety check: ensure no negative predictions)\n",
    "# final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "# 6. Create the final submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'Hospital_Id': submission_ids,\n",
    "    'Transport_Cost': final_predictions\n",
    "})\n",
    "\n",
    "# Display the first few predictions\n",
    "print(\"\\nFinal Predictions (in $):\")\n",
    "display(submission_df.head())\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('xgb.csv', index=False)\n",
    "print(\"Submission file 'xgb.csv' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MlLab)",
   "language": "python",
   "name": "mllab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
