{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: IMPORTS ===\n",
    "\n",
    "# core\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data + plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn (preprocessing / pipeline / model selection / metrics)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# NEW: Import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# models\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 2: INITIAL DATA LOAD & CLEANING ===\n",
    "\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv('../data/train.csv')\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print(f\"Initial data shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading '../data/train.csv'. Make sure the file is in the correct path.\")\n",
    "    print(e)\n",
    "\n",
    "# Clean all string/object columns\n",
    "print(\"Cleaning string columns...\")\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].replace({'': np.nan, 'nan': np.nan, 'NaN': np.nan})\n",
    "\n",
    "# Normalize Yes/No columns\n",
    "print(\"Normalizing Yes/No columns...\")\n",
    "yes_no_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',\n",
    "               'Fragile_Equipment', 'Rural_Hospital']\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    if col in yes_no_cols:\n",
    "        df[col] = df[col].replace({\n",
    "            'YES': 'Yes', 'yes': 'Yes', 'Y': 'Yes', 'y': 'Yes',\n",
    "            'NO': 'No', 'no': 'No', 'N': 'No', 'n': 'No'\n",
    "        })\n",
    "\n",
    "# Convert date columns\n",
    "print(\"Converting date columns...\")\n",
    "df['Order_Placed_Date'] = pd.to_datetime(df['Order_Placed_Date'], errors='coerce')\n",
    "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
    "\n",
    "# Create new features\n",
    "print(\"Engineering Delivery_Days and date features...\")\n",
    "df['Delivery_Days'] = (df['Delivery_Date'] - df['Order_Placed_Date']).dt.days\n",
    "df['Order_Month'] = df['Order_Placed_Date'].dt.month\n",
    "df['Order_Day_of_Week'] = df['Order_Placed_Date'].dt.dayofweek\n",
    "df['Order_Is_Weekend'] = df['Order_Day_of_Week'].isin([5, 6])\n",
    "\n",
    "print(\"\\nâœ… Initial load and feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: V4 ROBUST PREPROCESSING (USING ROBUSTSCALER) ===\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" V4 - ROBUST PREPROCESSING (NO CLIPPING, USING ROBUSTSCALER)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 1: PRE-SPLIT DATA CLEANING & FEATURE ENGINEERING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n[1/10] Repairing impossible negative values...\")\n",
    "# We STILL do this. This is correct.\n",
    "df['Delivery_Days'] = df['Delivery_Days'].abs()\n",
    "df['Transport_Cost'] = df['Transport_Cost'].abs()\n",
    "print(\"   âœ“ Repaired negative costs and durations using .abs()\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[2/10] Engineering features...\")\n",
    "df['Equipment_Volume'] = df['Equipment_Height'] * df['Equipment_Width']\n",
    "print(\"   âœ“ Created 'Equipment_Volume'\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[3/10] Log-transforming skewed features...\")\n",
    "# We no longer clip, just log-transform\n",
    "df['Equipment_Value'] = np.log1p(df['Equipment_Value'])\n",
    "df['Equipment_Volume'] = np.log1p(df['Equipment_Volume'])\n",
    "print(f\"   âœ“ Log-transformed 'Equipment_Value' and 'Equipment_Volume'\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[4/10] Defining target variable (y)...\")\n",
    "# We no longer clip, just log-transform the repaired target\n",
    "y = np.log1p(df['Transport_Cost'])\n",
    "print(f\"   âœ“ Target (y) created using log1p(abs(Transport_Cost))\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[5/10] Selecting features (X) for modeling...\")\n",
    "drop_cols = [\n",
    "    'Transport_Cost', 'Equipment_Height', 'Equipment_Width', 'Equipment_Weight',\n",
    "    'Hospital_Id', 'Supplier_Name', 'Hospital_Location',\n",
    "    'Order_Placed_Date', 'Delivery_Date'\n",
    "]\n",
    "X = df.drop(columns=drop_cols)\n",
    "print(f\"   âœ“ Selected {X.shape[1]} features.\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[6/10] Train-test split (80/20)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"   âœ“ Training set: {X_train.shape}\")\n",
    "print(f\"   âœ“ Test set:     {X_test.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: POST-SPLIT PIPELINES\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" BUILDING V4 ROBUST PIPELINES (USING ROBUSTSCALER)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[8/10] Configuring feature transformers...\")\n",
    "\n",
    "# --- Numeric Features ---\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability', 'Equipment_Value', 'Base_Transport_Fee',\n",
    "    'Delivery_Days', 'Equipment_Volume'\n",
    "]\n",
    "# === CRITICAL CHANGE: USE ROBUSTSCALER ===\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()) # Use RobustScaler instead of StandardScaler\n",
    "])\n",
    "print(f\"   âœ“ Numeric features: median imputation + RobustScaler\")\n",
    "\n",
    "# --- Categorical Features ---\n",
    "categorical_features = [\n",
    "    'Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping',\n",
    "    'Installation_Service', 'Transport_Method', 'Fragile_Equipment',\n",
    "    'Hospital_Info', 'Rural_Hospital', 'Order_Month',\n",
    "    'Order_Day_of_Week', 'Order_Is_Weekend'\n",
    "]\n",
    "# Use the 'Missing' category strategy\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "print(f\"   âœ“ Categorical features: imputing NaNs as 'Missing' + one-hot\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[9/10] Assembling ColumnTransformer...\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "print(f\"   âœ“ ColumnTransformer 'preprocessor' configured\")\n",
    "\n",
    "# ==============================================================================\n",
    "print(\"\\n[10/10] Applying preprocessing...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(f\"   âœ“ V4 Preprocessing complete.\")\n",
    "print(f\"   âœ“ Training set processed: {X_train_processed.shape}\")\n",
    "print(f\"   âœ“ Test set processed:     {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# === CELL 4 (V8): GRIDSEARCHCV FOR A SIMPLE RIDGE MODEL ===\n",
    "\n",
    "print(\"ðŸš€ Starting V8 GridSearchCV for Ridge (Focusing on EXTREME SIMPLICITY)...\")\n",
    "\n",
    "# --- 1. CV splitter ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 2. Ridge pipeline ---\n",
    "# 'preprocessor' is your V4 preprocessor (with RobustScaler)\n",
    "# This MUST be the V4 preprocessor object, already in your memory\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('ridge', Ridge(random_state=42)) # Simple, robust linear model\n",
    "])\n",
    "\n",
    "# --- 3. V8 Hyperparameter grid (Just tune regularization strength) ---\n",
    "param_grid = {\n",
    "    'ridge__alpha': [1, 10, 50, 100, 200, 500, 1000] # Test a wide range of L2 regularization\n",
    "}\n",
    "\n",
    "# --- 4. GridSearchCV ---\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- 5. Run grid search on the V4 TRAINING DATA ---\n",
    "# (X_train and y_train are from your V4 preprocessing cell)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Best params & CV score ---\n",
    "print(\"\\nâœ… V8 (Ridge) GridSearch complete!\")\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_rmse = -grid_search.best_score_\n",
    "print(f\"   Best hyperparameters: {best_params}\")\n",
    "print(f\"   Best CV RMSE (log-space): {best_cv_rmse:.4f}\")\n",
    "\n",
    "# --- 7. Evaluate on V4 test set ---\n",
    "final_ridge_v8 = grid_search.best_estimator_\n",
    "y_test_pred_log = final_ridge_v8.predict(X_test)\n",
    "y_test_pred_orig = np.expm1(y_test_pred_log)\n",
    "\n",
    "rmse_test_log = np.sqrt(mean_squared_error(y_test, y_test_pred_log))\n",
    "rmse_test_orig = np.sqrt(mean_squared_error(np.expm1(y_test), y_test_pred_orig))\n",
    "\n",
    "print(f\"\\n   Test RMSE (log-space)      : {rmse_test_log:.4f}\")\n",
    "print(f\"   Test RMSE (original scale) : {rmse_test_orig:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 5: DEFINE THE V4 'PREPARE_FEATURES' FUNCTION ===\n",
    "\n",
    "# This function is now simpler: no clipping!\n",
    "def prepare_features_V4(df_raw):\n",
    "    \"\"\"\n",
    "    Applies all V4 (robust) manual cleaning and feature engineering.\n",
    "    No clipping is needed as the RobustScaler pipeline handles outliers.\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # 2. Clean all string/object columns\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df[col] = df[col].replace({'': np.nan, 'nan': np.nan, 'NaN': np.nan})\n",
    "\n",
    "    # 3. Normalize Yes/No columns\n",
    "    yes_no_cols = ['CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service',\n",
    "                   'Fragile_Equipment', 'Rural_Hospital']\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        if col in yes_no_cols:\n",
    "            df[col] = df[col].replace({\n",
    "                'YES': 'Yes', 'yes': 'Yes', 'Y': 'Yes', 'y': 'Yes',\n",
    "                'NO': 'No', 'no': 'No', 'N': 'No', 'n': 'No'\n",
    "            })\n",
    "\n",
    "    # 4. Convert date columns\n",
    "    df['Order_Placed_Date'] = pd.to_datetime(df['Order_Placed_Date'], errors='coerce')\n",
    "    df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
    "\n",
    "    # 5. Engineer Date Features\n",
    "    df['Delivery_Days'] = (df['Delivery_Date'] - df['Order_Placed_Date']).dt.days\n",
    "    df['Delivery_Days'] = df['Delivery_Days'].abs() # V4 fix\n",
    "    df['Order_Month'] = df['Order_Placed_Date'].dt.month\n",
    "    df['Order_Day_of_Week'] = df['Order_Placed_Date'].dt.dayofweek\n",
    "    df['Order_Is_Weekend'] = df['Order_Day_of_Week'].isin([5, 6])\n",
    "    \n",
    "    # 7. ==== V4: ENGINEERING & LOG-TRANSFORM ====\n",
    "    df['Equipment_Volume'] = df['Equipment_Height'] * df['Equipment_Width']\n",
    "    df['Equipment_Value'] = np.log1p(df['Equipment_Value'])\n",
    "    df['Equipment_Volume'] = np.log1p(df['Equipment_Volume'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"   âœ“ V4 `prepare_features_V4` function created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf036a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 6: TRAIN YOUR FINAL, BEST V8 (RIDGE) MODEL ON ALL V4 DATA ===\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"\\nTraining final V8 (Ridge) model on all V4 data...\")\n",
    "print(\"--- THIS IS OUR 'ROBUST & SIMPLE' MODEL ---\")\n",
    "\n",
    "# === 1. Feature groups (from our V4 robust script) ===\n",
    "numeric_features = [\n",
    "    'Supplier_Reliability', 'Equipment_Value', 'Base_Transport_Fee',\n",
    "    'Delivery_Days', 'Equipment_Volume'\n",
    "]\n",
    "categorical_features = [\n",
    "    'Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping',\n",
    "    'Installation_Service', 'Transport_Method', 'Fragile_Equipment',\n",
    "    'Hospital_Info', 'Rural_Hospital', 'Order_Month',\n",
    "    'Order_Day_of_Week', 'Order_Is_Weekend'\n",
    "]\n",
    "\n",
    "# === 2. Define V4 transformers (with RobustScaler) ===\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()) # CRITICAL: Use RobustScaler\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# === 3. Combine them ===\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# === 4. Build final pipeline with BEST V8 hyperparameters ===\n",
    "# (This automatically uses the 'best_params' variable from Cell 4)\n",
    "print(f\"   âœ“ Using best params from V8 GridSearch: {best_params}\")\n",
    "\n",
    "final_ridge_v8_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', final_preprocessor),\n",
    "    ('ridge', Ridge(\n",
    "        alpha=best_params['ridge__alpha'], # Unpacks {'ridge__alpha': 10}\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# === 5. Fit on full V4 dataset ===\n",
    "# (X and y are from Cell 3)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "final_ridge_v8_pipeline.fit(X, y)\n",
    "\n",
    "print(\"\\nâœ… Final (V8 RIDGE) model trained on entire dataset.\")\n",
    "print(\"The 'final_ridge_v8_pipeline' object is ready for prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7777260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 7: GENERATE YOUR FINAL V4 SUBMISSION ===\n",
    "\n",
    "# 1. Load your new, raw test data\n",
    "print(\"Loading new test data (test.csv)...\")\n",
    "df_new_test = pd.read_csv('../data/test.csv') \n",
    "\n",
    "# 2. Save IDs\n",
    "submission_ids = df_new_test['Hospital_Id']\n",
    "\n",
    "# 3. Apply the *V4* feature engineering\n",
    "print(\"Applying V4 (RobustScaler) feature engineering...\")\n",
    "# This uses the 'prepare_features_V4' function you defined in Cell 5\n",
    "X_new_prepared = prepare_features_V4(df_new_test) \n",
    "\n",
    "# 4. Get predictions FROM THE ROBUST V4 MODEL\n",
    "print(\"Getting predictions from the final V4 XGBoost model...\")\n",
    "# This uses the 'final_xgb_robust_pipeline_V4' model from Cell 6\n",
    "log_predictions = final_xgb_robust_pipeline_V4.predict(X_new_prepared)\n",
    "\n",
    "# 5. Convert predictions back from log-scale\n",
    "final_predictions = np.expm1(log_predictions)\n",
    "\n",
    "# 6. Create the final submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'Hospital_Id': submission_ids,\n",
    "    'Transport_Cost': final_predictions\n",
    "})\n",
    "\n",
    "# Display the first few predictions\n",
    "print(\"\\nFinal Predictions:\")\n",
    "display(submission_df.head())\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('submission_XGB_V4_RobustScaler.csv', index=False)\n",
    "print(\"\\nâœ… Submission file 'submission_XGB_V4_RobustScaler.csv' created successfully.\")\n",
    "print(\"THIS IS THE ONE. UPLOAD THIS FILE TO KAGGLE!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
