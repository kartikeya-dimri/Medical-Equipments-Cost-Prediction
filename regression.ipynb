{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b735fcb7",
   "metadata": {},
   "source": [
    "# Medical Equipment Cost Prediction - Linear Regression\n",
    "\n",
    "This notebook performs linear regression with proper data preprocessing including:\n",
    "- Missing data handling\n",
    "- Outlier detection and treatment\n",
    "- Feature engineering\n",
    "- Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9111419",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc12d9",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab158f",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd552a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(train_df.info())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(train_df.describe())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nTarget Variable Statistics:\")\n",
    "print(train_df['Transport_Cost'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Count:\")\n",
    "missing_counts = train_df.isnull().sum()\n",
    "missing_percentage = (missing_counts / len(train_df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_counts,\n",
    "    'Percentage': missing_percentage\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d71cca",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "train_clean = train_df.copy()\n",
    "test_clean = test_df.copy()\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = train_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variable from numerical columns\n",
    "if 'Transport_Cost' in numerical_cols:\n",
    "    numerical_cols.remove('Transport_Cost')\n",
    "\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols[:5]}...\")\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols[:5]}...\")\n",
    "\n",
    "# Handle missing values in numerical columns - use median\n",
    "for col in numerical_cols:\n",
    "    if train_clean[col].isnull().sum() > 0:\n",
    "        median_val = train_clean[col].median()\n",
    "        train_clean[col].fillna(median_val, inplace=True)\n",
    "        test_clean[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# Handle missing values in categorical columns - use mode\n",
    "for col in categorical_cols:\n",
    "    if train_clean[col].isnull().sum() > 0:\n",
    "        mode_val = train_clean[col].mode()[0] if len(train_clean[col].mode()) > 0 else 'Unknown'\n",
    "        train_clean[col].fillna(mode_val, inplace=True)\n",
    "        test_clean[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"Filled {col} with mode: {mode_val}\")\n",
    "\n",
    "print(f\"\\nMissing values after handling: {train_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03b160",
   "metadata": {},
   "source": [
    "## 5. Detect and Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ddd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers in target variable\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Boxplot\n",
    "axes[0].boxplot(train_clean['Transport_Cost'])\n",
    "axes[0].set_title('Transport Cost - Boxplot')\n",
    "axes[0].set_ylabel('Transport Cost')\n",
    "\n",
    "# Histogram\n",
    "axes[1].hist(train_clean['Transport_Cost'], bins=50, edgecolor='black')\n",
    "axes[1].set_title('Transport Cost - Distribution')\n",
    "axes[1].set_xlabel('Transport Cost')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Transport Cost Statistics:\")\n",
    "print(f\"Mean: {train_clean['Transport_Cost'].mean():.2f}\")\n",
    "print(f\"Median: {train_clean['Transport_Cost'].median():.2f}\")\n",
    "print(f\"Std: {train_clean['Transport_Cost'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15012730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method for numerical features\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Check outliers in target variable\n",
    "outliers, lower, upper = detect_outliers_iqr(train_clean, 'Transport_Cost')\n",
    "print(f\"Outliers in Transport_Cost: {len(outliers)} ({len(outliers)/len(train_clean)*100:.2f}%)\")\n",
    "print(f\"Lower bound: {lower:.2f}, Upper bound: {upper:.2f}\")\n",
    "\n",
    "# Handle outliers using capping (Winsorization)\n",
    "print(\"\\nHandling outliers using capping method...\")\n",
    "train_clean['Transport_Cost'] = np.where(\n",
    "    train_clean['Transport_Cost'] > upper, \n",
    "    upper, \n",
    "    train_clean['Transport_Cost']\n",
    ")\n",
    "train_clean['Transport_Cost'] = np.where(\n",
    "    train_clean['Transport_Cost'] < lower, \n",
    "    lower, \n",
    "    train_clean['Transport_Cost']\n",
    ")\n",
    "\n",
    "print(f\"After capping - Min: {train_clean['Transport_Cost'].min():.2f}, Max: {train_clean['Transport_Cost'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd62aa",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91457d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "train_clean['Order_Placed_Date'] = pd.to_datetime(train_clean['Order_Placed_Date'])\n",
    "train_clean['Delivery_Date'] = pd.to_datetime(train_clean['Delivery_Date'])\n",
    "test_clean['Order_Placed_Date'] = pd.to_datetime(test_clean['Order_Placed_Date'])\n",
    "test_clean['Delivery_Date'] = pd.to_datetime(test_clean['Delivery_Date'])\n",
    "\n",
    "# Create new features\n",
    "train_clean['Delivery_Days'] = (train_clean['Delivery_Date'] - train_clean['Order_Placed_Date']).dt.days\n",
    "test_clean['Delivery_Days'] = (test_clean['Delivery_Date'] - test_clean['Order_Placed_Date']).dt.days\n",
    "\n",
    "# Create equipment volume feature\n",
    "train_clean['Equipment_Volume'] = train_clean['Equipment_Height'] * train_clean['Equipment_Width']\n",
    "test_clean['Equipment_Volume'] = test_clean['Equipment_Height'] * test_clean['Equipment_Width']\n",
    "\n",
    "# Drop date columns as they are not needed for regression\n",
    "train_clean = train_clean.drop(['Order_Placed_Date', 'Delivery_Date'], axis=1)\n",
    "test_clean = test_clean.drop(['Order_Placed_Date', 'Delivery_Date'], axis=1)\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- Delivery_Days\")\n",
    "print(\"- Equipment_Volume\")\n",
    "print(f\"\\nUpdated shape: {train_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7674d8f",
   "metadata": {},
   "source": [
    "## 7. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f052a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical columns (excluding IDs and location which are too many unique values)\n",
    "categorical_to_encode = ['Supplier_Name', 'Equipment_Type', 'CrossBorder_Shipping', \n",
    "                         'Urgent_Shipping', 'Installation_Service', 'Transport_Method',\n",
    "                         'Fragile_Equipment', 'Hospital_Info', 'Rural_Hospital']\n",
    "\n",
    "# Use Label Encoding for categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_to_encode:\n",
    "    if col in train_clean.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on combined data to ensure same encoding\n",
    "        combined = pd.concat([train_clean[col].astype(str), test_clean[col].astype(str)])\n",
    "        le.fit(combined)\n",
    "        train_clean[col] = le.transform(train_clean[col].astype(str))\n",
    "        test_clean[col] = le.transform(test_clean[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "# Drop high cardinality columns that won't help regression\n",
    "cols_to_drop = ['Hospital_Id', 'Hospital_Location']\n",
    "train_clean = train_clean.drop(cols_to_drop, axis=1)\n",
    "test_clean = test_clean.drop(cols_to_drop, axis=1)\n",
    "\n",
    "print(f\"\\nFinal shape after encoding: {train_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761d6ae",
   "metadata": {},
   "source": [
    "## 8. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50973204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = train_clean.drop('Transport_Cost', axis=1)\n",
    "y = train_clean['Transport_Cost']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")\n",
    "print(f\"\\nFeatures used for modeling: {X.shape[1]}\")\n",
    "print(f\"Feature names: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da31b68",
   "metadata": {},
   "source": [
    "## 9. Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Linear Regression model\n",
    "print(\"Training Linear Regression model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_val_pred = lr_model.predict(X_val)\n",
    "\n",
    "print(\"\\nModel coefficients (top 10):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86121547",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation - Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b926e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"LINEAR REGRESSION MODEL - PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTRAINING SET METRICS:\")\n",
    "print(f\"  R¬≤ Score (R-squared):        {train_r2:.4f}\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): {train_rmse:.2f}\")\n",
    "print(f\"  MAE (Mean Absolute Error):   {train_mae:.2f}\")\n",
    "\n",
    "print(\"\\nVALIDATION SET METRICS:\")\n",
    "print(f\"  R¬≤ Score (R-squared):        {val_r2:.4f}\")\n",
    "print(f\"  RMSE (Root Mean Squared Error): {val_rmse:.2f}\")\n",
    "print(f\"  MAE (Mean Absolute Error):   {val_mae:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"FINAL SCORE (Validation R¬≤): {val_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for overfitting\n",
    "print(f\"\\nOverfitting Check:\")\n",
    "print(f\"  Difference in R¬≤: {abs(train_r2 - val_r2):.4f}\")\n",
    "if abs(train_r2 - val_r2) < 0.05:\n",
    "    print(\"  Status: Good - Minimal overfitting\")\n",
    "elif abs(train_r2 - val_r2) < 0.10:\n",
    "    print(\"  Status: Moderate - Some overfitting\")\n",
    "else:\n",
    "    print(\"  Status: High - Significant overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2a78d",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a72d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of predictions vs actual values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot - Validation Set\n",
    "axes[0].scatter(y_val, y_val_pred, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Transport Cost', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[0].set_title(f'Validation Set: Actual vs Predicted\\nR¬≤ = {val_r2:.4f}', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_val - y_val_pred\n",
    "axes[1].scatter(y_val_pred, residuals, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot (Validation Set)', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff511cbb",
   "metadata": {},
   "source": [
    "## 12. Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae379a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary\n",
    "summary = {\n",
    "    'Data Preprocessing': {\n",
    "        'Original Training Samples': len(train_df),\n",
    "        'Features Used': X.shape[1],\n",
    "        'Missing Values Handled': 'Yes (Median for numerical, Mode for categorical)',\n",
    "        'Outliers Handled': 'Yes (IQR capping method)',\n",
    "        'Feature Engineering': 'Delivery_Days, Equipment_Volume'\n",
    "    },\n",
    "    'Model Performance': {\n",
    "        'Training R¬≤ Score': f'{train_r2:.4f}',\n",
    "        'Validation R¬≤ Score': f'{val_r2:.4f}',\n",
    "        'Training RMSE': f'{train_rmse:.2f}',\n",
    "        'Validation RMSE': f'{val_rmse:.2f}',\n",
    "        'Training MAE': f'{train_mae:.2f}',\n",
    "        'Validation MAE': f'{val_mae:.2f}'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MEDICAL EQUIPMENT COST PREDICTION - LINEAR REGRESSION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for section, metrics in summary.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    print(\"-\" * 70)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key:.<50} {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"FINAL MODEL SCORE (Validation R¬≤): {val_r2:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - The model explains {val_r2*100:.2f}% of the variance in Transport Cost\")\n",
    "print(f\"  - Average prediction error (MAE): ¬±{val_mae:.2f} units\")\n",
    "print(f\"  - Root mean squared error (RMSE): {val_rmse:.2f} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8075b9",
   "metadata": {},
   "source": [
    "## 13. Polynomial Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5222cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"Testing Polynomial Regression with degrees from 1 to 5...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store results for each degree\n",
    "poly_results = {\n",
    "    'degree': [],\n",
    "    'train_r2': [],\n",
    "    'val_r2': [],\n",
    "    'train_rmse': [],\n",
    "    'val_rmse': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': []\n",
    "}\n",
    "\n",
    "# Test polynomial degrees from 1 to 10\n",
    "for degree in range(1, 6):\n",
    "    print(f\"\\nTesting Polynomial Degree: {degree}\")\n",
    "    \n",
    "    # Create polynomial features and model pipeline\n",
    "    poly_model = Pipeline([\n",
    "        ('poly_features', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        ('linear_regression', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    poly_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_poly = poly_model.predict(X_train)\n",
    "    y_val_pred_poly = poly_model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2_poly = r2_score(y_train, y_train_pred_poly)\n",
    "    val_r2_poly = r2_score(y_val, y_val_pred_poly)\n",
    "    train_rmse_poly = np.sqrt(mean_squared_error(y_train, y_train_pred_poly))\n",
    "    val_rmse_poly = np.sqrt(mean_squared_error(y_val, y_val_pred_poly))\n",
    "    train_mae_poly = mean_absolute_error(y_train, y_train_pred_poly)\n",
    "    val_mae_poly = mean_absolute_error(y_val, y_val_pred_poly)\n",
    "    \n",
    "    # Store results\n",
    "    poly_results['degree'].append(degree)\n",
    "    poly_results['train_r2'].append(train_r2_poly)\n",
    "    poly_results['val_r2'].append(val_r2_poly)\n",
    "    poly_results['train_rmse'].append(train_rmse_poly)\n",
    "    poly_results['val_rmse'].append(val_rmse_poly)\n",
    "    poly_results['train_mae'].append(train_mae_poly)\n",
    "    poly_results['val_mae'].append(val_mae_poly)\n",
    "    \n",
    "    print(f\"  Train R¬≤: {train_r2_poly:.4f} | Val R¬≤: {val_r2_poly:.4f}\")\n",
    "    print(f\"  Train RMSE: {train_rmse_poly:.2f} | Val RMSE: {val_rmse_poly:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Hyperparameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ffdfb",
   "metadata": {},
   "source": [
    "## 14. Visualize Polynomial Degree Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1693e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "poly_results_df = pd.DataFrame(poly_results)\n",
    "print(\"Polynomial Regression Results:\")\n",
    "print(poly_results_df.to_string(index=False))\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: R¬≤ Score vs Degree\n",
    "axes[0, 0].plot(poly_results_df['degree'], poly_results_df['train_r2'], \n",
    "                marker='o', label='Training R¬≤', linewidth=2, markersize=8)\n",
    "axes[0, 0].plot(poly_results_df['degree'], poly_results_df['val_r2'], \n",
    "                marker='s', label='Validation R¬≤', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[0, 0].set_ylabel('R¬≤ Score', fontsize=12)\n",
    "axes[0, 0].set_title('R¬≤ Score vs Polynomial Degree', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xticks(range(1, 6))\n",
    "\n",
    "# Plot 2: RMSE vs Degree\n",
    "axes[0, 1].plot(poly_results_df['degree'], poly_results_df['train_rmse'], \n",
    "                marker='o', label='Training RMSE', linewidth=2, markersize=8)\n",
    "axes[0, 1].plot(poly_results_df['degree'], poly_results_df['val_rmse'], \n",
    "                marker='s', label='Validation RMSE', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[0, 1].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0, 1].set_title('RMSE vs Polynomial Degree', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xticks(range(1, 6))\n",
    "\n",
    "# Plot 3: MAE vs Degree\n",
    "axes[1, 0].plot(poly_results_df['degree'], poly_results_df['train_mae'], \n",
    "                marker='o', label='Training MAE', linewidth=2, markersize=8)\n",
    "axes[1, 0].plot(poly_results_df['degree'], poly_results_df['val_mae'], \n",
    "                marker='s', label='Validation MAE', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[1, 0].set_ylabel('MAE', fontsize=12)\n",
    "axes[1, 0].set_title('MAE vs Polynomial Degree', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xticks(range(1, 6))\n",
    "\n",
    "# Plot 4: Overfitting Analysis (Train vs Val R¬≤ difference)\n",
    "r2_diff = [abs(t - v) for t, v in zip(poly_results_df['train_r2'], poly_results_df['val_r2'])]\n",
    "axes[1, 1].bar(poly_results_df['degree'], r2_diff, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].axhline(y=0.05, color='red', linestyle='--', label='Acceptable threshold (0.05)', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Polynomial Degree', fontsize=12)\n",
    "axes[1, 1].set_ylabel('|Train R¬≤ - Val R¬≤|', fontsize=12)\n",
    "axes[1, 1].set_title('Overfitting Analysis', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 1].set_xticks(range(1, 6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e470497",
   "metadata": {},
   "source": [
    "## 15. Select Best Polynomial Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4deb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best polynomial degree based on validation R¬≤\n",
    "best_idx = poly_results_df['val_r2'].idxmax()\n",
    "best_degree = poly_results_df.loc[best_idx, 'degree']\n",
    "best_val_r2 = poly_results_df.loc[best_idx, 'val_r2']\n",
    "best_val_rmse = poly_results_df.loc[best_idx, 'val_rmse']\n",
    "best_val_mae = poly_results_df.loc[best_idx, 'val_mae']\n",
    "best_train_r2 = poly_results_df.loc[best_idx, 'train_r2']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BEST POLYNOMIAL DEGREE SELECTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest Polynomial Degree: {best_degree}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Validation R¬≤ Score:  {best_val_r2:.4f}\")\n",
    "print(f\"  Training R¬≤ Score:    {best_train_r2:.4f}\")\n",
    "print(f\"  Validation RMSE:      {best_val_rmse:.2f}\")\n",
    "print(f\"  Validation MAE:       {best_val_mae:.2f}\")\n",
    "print(f\"  Overfitting Gap:      {abs(best_train_r2 - best_val_r2):.4f}\")\n",
    "\n",
    "# Compare with linear regression (degree 1)\n",
    "linear_val_r2 = poly_results_df.loc[0, 'val_r2']\n",
    "improvement = ((best_val_r2 - linear_val_r2) / linear_val_r2) * 100\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON WITH LINEAR REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Linear Regression (Degree 1) Val R¬≤:  {linear_val_r2:.4f}\")\n",
    "print(f\"Best Polynomial (Degree {best_degree}) Val R¬≤:   {best_val_r2:.4f}\")\n",
    "print(f\"Improvement:                           {improvement:+.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db7fd4",
   "metadata": {},
   "source": [
    "## 16. Train Final Best Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best degree\n",
    "print(f\"Training final Polynomial Regression model with degree {best_degree}...\")\n",
    "\n",
    "best_poly_model = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=int(best_degree), include_bias=False)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "best_poly_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_best = best_poly_model.predict(X_train)\n",
    "y_val_pred_best = best_poly_model.predict(X_val)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_train_r2 = r2_score(y_train, y_train_pred_best)\n",
    "final_val_r2 = r2_score(y_val, y_val_pred_best)\n",
    "final_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_best))\n",
    "final_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_best))\n",
    "final_train_mae = mean_absolute_error(y_train, y_train_pred_best)\n",
    "final_val_mae = mean_absolute_error(y_val, y_val_pred_best)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"\\nNumber of polynomial features created: {best_poly_model.named_steps['poly_features'].n_output_features_}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"POLYNOMIAL REGRESSION (Degree {int(best_degree)}) - FINAL PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTRAINING SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {final_train_r2:.4f}\")\n",
    "print(f\"  RMSE:      {final_train_rmse:.2f}\")\n",
    "print(f\"  MAE:       {final_train_mae:.2f}\")\n",
    "\n",
    "print(\"\\nVALIDATION SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {final_val_r2:.4f}\")\n",
    "print(f\"  RMSE:      {final_val_rmse:.2f}\")\n",
    "print(f\"  MAE:       {final_val_mae:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"FINAL SCORE (Validation R¬≤): {final_val_r2:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115afa24",
   "metadata": {},
   "source": [
    "## 17. Visualize Best Polynomial Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of best polynomial model predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot - Validation Set\n",
    "axes[0].scatter(y_val, y_val_pred_best, alpha=0.5, edgecolors='k', linewidth=0.5, color='green')\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Transport Cost', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[0].set_title(f'Polynomial Regression (Degree {int(best_degree)}): Actual vs Predicted\\nR¬≤ = {final_val_r2:.4f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals_poly = y_val - y_val_pred_best\n",
    "axes[1].scatter(y_val_pred_best, residuals_poly, alpha=0.5, edgecolors='k', linewidth=0.5, color='purple')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title(f'Residual Plot - Polynomial Degree {int(best_degree)} (Validation Set)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print residual statistics\n",
    "print(\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean of Residuals:     {residuals_poly.mean():.4f}\")\n",
    "print(f\"  Std of Residuals:      {residuals_poly.std():.2f}\")\n",
    "print(f\"  Min Residual:          {residuals_poly.min():.2f}\")\n",
    "print(f\"  Max Residual:          {residuals_poly.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798e920",
   "metadata": {},
   "source": [
    "## 18. Final Comparison: Linear vs Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "comparison_data = {\n",
    "    'Model': ['Linear Regression', f'Polynomial Regression (Degree {int(best_degree)})'],\n",
    "    'Train R¬≤': [train_r2, final_train_r2],\n",
    "    'Validation R¬≤': [val_r2, final_val_r2],\n",
    "    'Train RMSE': [train_rmse, final_train_rmse],\n",
    "    'Validation RMSE': [val_rmse, final_val_rmse],\n",
    "    'Train MAE': [train_mae, final_train_mae],\n",
    "    'Validation MAE': [val_mae, final_val_mae],\n",
    "    'Overfitting Gap': [abs(train_r2 - val_r2), abs(final_train_r2 - final_val_r2)]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL MODEL COMPARISON: LINEAR vs POLYNOMIAL REGRESSION\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Determine the best model\n",
    "if final_val_r2 > val_r2:\n",
    "    winner = f'Polynomial Regression (Degree {int(best_degree)})'\n",
    "    improvement_pct = ((final_val_r2 - val_r2) / val_r2) * 100\n",
    "    print(f\"\\nüèÜ WINNER: {winner}\")\n",
    "    print(f\"   Improvement over Linear Regression: {improvement_pct:.2f}%\")\n",
    "else:\n",
    "    winner = 'Linear Regression'\n",
    "    print(f\"\\nüèÜ WINNER: {winner}\")\n",
    "    print(\"   Linear Regression performs better or equally well.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*90)\n",
    "print(f\"‚úì Best Model: {winner}\")\n",
    "print(f\"‚úì Validation R¬≤ Score: {max(val_r2, final_val_r2):.4f}\")\n",
    "print(f\"‚úì Validation RMSE: {min(val_rmse, final_val_rmse):.2f}\")\n",
    "print(f\"‚úì Validation MAE: {min(val_mae, final_val_mae):.2f}\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba915cd0",
   "metadata": {},
   "source": [
    "## 19. Ridge Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c285c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use polynomial features from best degree\n",
    "print(f\"Using Polynomial Features with Degree {int(best_degree)} for Regularized Models\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create polynomial features\n",
    "poly_features = PolynomialFeatures(degree=int(best_degree), include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_val_poly = poly_features.transform(X_val)\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Polynomial features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "# Ridge Regression - Hyperparameter Tuning\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RIDGE REGRESSION - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define alpha values to test\n",
    "ridge_alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "ridge_results = {\n",
    "    'alpha': [],\n",
    "    'train_r2': [],\n",
    "    'val_r2': [],\n",
    "    'train_rmse': [],\n",
    "    'val_rmse': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': []\n",
    "}\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    ridge_model = Ridge(alpha=alpha, random_state=42)\n",
    "    ridge_model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    y_train_pred_ridge = ridge_model.predict(X_train_poly)\n",
    "    y_val_pred_ridge = ridge_model.predict(X_val_poly)\n",
    "    \n",
    "    train_r2_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "    val_r2_ridge = r2_score(y_val, y_val_pred_ridge)\n",
    "    train_rmse_ridge = np.sqrt(mean_squared_error(y_train, y_train_pred_ridge))\n",
    "    val_rmse_ridge = np.sqrt(mean_squared_error(y_val, y_val_pred_ridge))\n",
    "    train_mae_ridge = mean_absolute_error(y_train, y_train_pred_ridge)\n",
    "    val_mae_ridge = mean_absolute_error(y_val, y_val_pred_ridge)\n",
    "    \n",
    "    ridge_results['alpha'].append(alpha)\n",
    "    ridge_results['train_r2'].append(train_r2_ridge)\n",
    "    ridge_results['val_r2'].append(val_r2_ridge)\n",
    "    ridge_results['train_rmse'].append(train_rmse_ridge)\n",
    "    ridge_results['val_rmse'].append(val_rmse_ridge)\n",
    "    ridge_results['train_mae'].append(train_mae_ridge)\n",
    "    ridge_results['val_mae'].append(val_mae_ridge)\n",
    "    \n",
    "    print(f\"Alpha={alpha:7.3f} | Train R¬≤: {train_r2_ridge:.4f} | Val R¬≤: {val_r2_ridge:.4f}\")\n",
    "\n",
    "ridge_results_df = pd.DataFrame(ridge_results)\n",
    "best_ridge_idx = ridge_results_df['val_r2'].idxmax()\n",
    "best_ridge_alpha = ridge_results_df.loc[best_ridge_idx, 'alpha']\n",
    "best_ridge_val_r2 = ridge_results_df.loc[best_ridge_idx, 'val_r2']\n",
    "\n",
    "print(f\"\\nBest Ridge Alpha: {best_ridge_alpha}\")\n",
    "print(f\"Best Validation R¬≤: {best_ridge_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97060f5b",
   "metadata": {},
   "source": [
    "## 20. Lasso Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression - Hyperparameter Tuning\n",
    "print(\"=\"*70)\n",
    "print(\"LASSO REGRESSION - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define alpha values to test\n",
    "lasso_alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "lasso_results = {\n",
    "    'alpha': [],\n",
    "    'train_r2': [],\n",
    "    'val_r2': [],\n",
    "    'train_rmse': [],\n",
    "    'val_rmse': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': []\n",
    "}\n",
    "\n",
    "for alpha in lasso_alphas:\n",
    "    lasso_model = Lasso(alpha=alpha, random_state=42, max_iter=10000)\n",
    "    lasso_model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    y_train_pred_lasso = lasso_model.predict(X_train_poly)\n",
    "    y_val_pred_lasso = lasso_model.predict(X_val_poly)\n",
    "    \n",
    "    train_r2_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "    val_r2_lasso = r2_score(y_val, y_val_pred_lasso)\n",
    "    train_rmse_lasso = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso))\n",
    "    val_rmse_lasso = np.sqrt(mean_squared_error(y_val, y_val_pred_lasso))\n",
    "    train_mae_lasso = mean_absolute_error(y_train, y_train_pred_lasso)\n",
    "    val_mae_lasso = mean_absolute_error(y_val, y_val_pred_lasso)\n",
    "    \n",
    "    lasso_results['alpha'].append(alpha)\n",
    "    lasso_results['train_r2'].append(train_r2_lasso)\n",
    "    lasso_results['val_r2'].append(val_r2_lasso)\n",
    "    lasso_results['train_rmse'].append(train_rmse_lasso)\n",
    "    lasso_results['val_rmse'].append(val_rmse_lasso)\n",
    "    lasso_results['train_mae'].append(train_mae_lasso)\n",
    "    lasso_results['val_mae'].append(val_mae_lasso)\n",
    "    \n",
    "    print(f\"Alpha={alpha:7.3f} | Train R¬≤: {train_r2_lasso:.4f} | Val R¬≤: {val_r2_lasso:.4f}\")\n",
    "\n",
    "lasso_results_df = pd.DataFrame(lasso_results)\n",
    "best_lasso_idx = lasso_results_df['val_r2'].idxmax()\n",
    "best_lasso_alpha = lasso_results_df.loc[best_lasso_idx, 'alpha']\n",
    "best_lasso_val_r2 = lasso_results_df.loc[best_lasso_idx, 'val_r2']\n",
    "\n",
    "print(f\"\\nBest Lasso Alpha: {best_lasso_alpha}\")\n",
    "print(f\"Best Validation R¬≤: {best_lasso_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c09df",
   "metadata": {},
   "source": [
    "## 21. ElasticNet Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet Regression - Hyperparameter Tuning\n",
    "print(\"=\"*70)\n",
    "print(\"ELASTICNET REGRESSION - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define alpha and l1_ratio values to test\n",
    "elasticnet_alphas = [0.001, 0.01, 0.1, 1, 10]\n",
    "l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "elasticnet_results = {\n",
    "    'alpha': [],\n",
    "    'l1_ratio': [],\n",
    "    'train_r2': [],\n",
    "    'val_r2': [],\n",
    "    'train_rmse': [],\n",
    "    'val_rmse': [],\n",
    "    'train_mae': [],\n",
    "    'val_mae': []\n",
    "}\n",
    "\n",
    "print(\"\\nTesting combinations of alpha and l1_ratio...\")\n",
    "for alpha in elasticnet_alphas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        elasticnet_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42, max_iter=10000)\n",
    "        elasticnet_model.fit(X_train_poly, y_train)\n",
    "        \n",
    "        y_train_pred_en = elasticnet_model.predict(X_train_poly)\n",
    "        y_val_pred_en = elasticnet_model.predict(X_val_poly)\n",
    "        \n",
    "        train_r2_en = r2_score(y_train, y_train_pred_en)\n",
    "        val_r2_en = r2_score(y_val, y_val_pred_en)\n",
    "        train_rmse_en = np.sqrt(mean_squared_error(y_train, y_train_pred_en))\n",
    "        val_rmse_en = np.sqrt(mean_squared_error(y_val, y_val_pred_en))\n",
    "        train_mae_en = mean_absolute_error(y_train, y_train_pred_en)\n",
    "        val_mae_en = mean_absolute_error(y_val, y_val_pred_en)\n",
    "        \n",
    "        elasticnet_results['alpha'].append(alpha)\n",
    "        elasticnet_results['l1_ratio'].append(l1_ratio)\n",
    "        elasticnet_results['train_r2'].append(train_r2_en)\n",
    "        elasticnet_results['val_r2'].append(val_r2_en)\n",
    "        elasticnet_results['train_rmse'].append(train_rmse_en)\n",
    "        elasticnet_results['val_rmse'].append(val_rmse_en)\n",
    "        elasticnet_results['train_mae'].append(train_mae_en)\n",
    "        elasticnet_results['val_mae'].append(val_mae_en)\n",
    "\n",
    "elasticnet_results_df = pd.DataFrame(elasticnet_results)\n",
    "best_en_idx = elasticnet_results_df['val_r2'].idxmax()\n",
    "best_en_alpha = elasticnet_results_df.loc[best_en_idx, 'alpha']\n",
    "best_en_l1_ratio = elasticnet_results_df.loc[best_en_idx, 'l1_ratio']\n",
    "best_en_val_r2 = elasticnet_results_df.loc[best_en_idx, 'val_r2']\n",
    "\n",
    "print(f\"\\nTop 5 ElasticNet Configurations:\")\n",
    "print(elasticnet_results_df.nlargest(5, 'val_r2')[['alpha', 'l1_ratio', 'val_r2', 'val_rmse']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nBest ElasticNet Alpha: {best_en_alpha}\")\n",
    "print(f\"Best ElasticNet L1 Ratio: {best_en_l1_ratio}\")\n",
    "print(f\"Best Validation R¬≤: {best_en_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed5cd2",
   "metadata": {},
   "source": [
    "## 22. Visualize Regularization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Ridge and Lasso performance across different alphas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Ridge: R¬≤ vs Alpha\n",
    "axes[0, 0].semilogx(ridge_results_df['alpha'], ridge_results_df['train_r2'], \n",
    "                    marker='o', label='Training R¬≤', linewidth=2, markersize=8)\n",
    "axes[0, 0].semilogx(ridge_results_df['alpha'], ridge_results_df['val_r2'], \n",
    "                    marker='s', label='Validation R¬≤', linewidth=2, markersize=8)\n",
    "axes[0, 0].axvline(x=best_ridge_alpha, color='red', linestyle='--', label=f'Best Œ±={best_ridge_alpha}')\n",
    "axes[0, 0].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('R¬≤ Score', fontsize=12)\n",
    "axes[0, 0].set_title('Ridge Regression: R¬≤ vs Alpha', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ridge: RMSE vs Alpha\n",
    "axes[0, 1].semilogx(ridge_results_df['alpha'], ridge_results_df['train_rmse'], \n",
    "                    marker='o', label='Training RMSE', linewidth=2, markersize=8)\n",
    "axes[0, 1].semilogx(ridge_results_df['alpha'], ridge_results_df['val_rmse'], \n",
    "                    marker='s', label='Validation RMSE', linewidth=2, markersize=8)\n",
    "axes[0, 1].axvline(x=best_ridge_alpha, color='red', linestyle='--', label=f'Best Œ±={best_ridge_alpha}')\n",
    "axes[0, 1].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0, 1].set_title('Ridge Regression: RMSE vs Alpha', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Lasso: R¬≤ vs Alpha\n",
    "axes[1, 0].semilogx(lasso_results_df['alpha'], lasso_results_df['train_r2'], \n",
    "                    marker='o', label='Training R¬≤', linewidth=2, markersize=8, color='green')\n",
    "axes[1, 0].semilogx(lasso_results_df['alpha'], lasso_results_df['val_r2'], \n",
    "                    marker='s', label='Validation R¬≤', linewidth=2, markersize=8, color='orange')\n",
    "axes[1, 0].axvline(x=best_lasso_alpha, color='red', linestyle='--', label=f'Best Œ±={best_lasso_alpha}')\n",
    "axes[1, 0].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('R¬≤ Score', fontsize=12)\n",
    "axes[1, 0].set_title('Lasso Regression: R¬≤ vs Alpha', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Lasso: RMSE vs Alpha\n",
    "axes[1, 1].semilogx(lasso_results_df['alpha'], lasso_results_df['train_rmse'], \n",
    "                    marker='o', label='Training RMSE', linewidth=2, markersize=8, color='green')\n",
    "axes[1, 1].semilogx(lasso_results_df['alpha'], lasso_results_df['val_rmse'], \n",
    "                    marker='s', label='Validation RMSE', linewidth=2, markersize=8, color='orange')\n",
    "axes[1, 1].axvline(x=best_lasso_alpha, color='red', linestyle='--', label=f'Best Œ±={best_lasso_alpha}')\n",
    "axes[1, 1].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('RMSE', fontsize=12)\n",
    "axes[1, 1].set_title('Lasso Regression: RMSE vs Alpha', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921d20e",
   "metadata": {},
   "source": [
    "## 23. Decision Tree Regression with Comprehensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a295c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DECISION TREE REGRESSION - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUsing GridSearchCV for comprehensive hyperparameter optimization...\")\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_leaf_nodes': [10, 20, 50, 100, None],\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'ccp_alpha': [0.0, 0.001, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Use polynomial features for decision tree as well\n",
    "print(f\"Using Polynomial Features with Degree {int(best_degree)}\")\n",
    "print(f\"Training features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "# Initialize Decision Tree Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "print(\"\\nPerforming GridSearchCV (this may take a few minutes)...\")\n",
    "print(f\"Total combinations to test: {5 * 4 * 4 * 5 * 2 * 3 * 5} = {5 * 4 * 4 * 5 * 2 * 3 * 5}\")\n",
    "\n",
    "dt_grid_search = GridSearchCV(\n",
    "    estimator=dt_regressor,\n",
    "    param_grid=dt_param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "dt_grid_search.fit(X_train_poly, y_train)\n",
    "\n",
    "print(\"\\nGridSearchCV completed!\")\n",
    "print(f\"Best parameters found: {dt_grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation R¬≤ score: {dt_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f1c2b",
   "metadata": {},
   "source": [
    "## 24. Evaluate Best Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eca141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "best_dt_model = dt_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_dt = best_dt_model.predict(X_train_poly)\n",
    "y_val_pred_dt = best_dt_model.predict(X_val_poly)\n",
    "\n",
    "# Calculate metrics\n",
    "dt_train_r2 = r2_score(y_train, y_train_pred_dt)\n",
    "dt_val_r2 = r2_score(y_val, y_val_pred_dt)\n",
    "dt_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_dt))\n",
    "dt_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_dt))\n",
    "dt_train_mae = mean_absolute_error(y_train, y_train_pred_dt)\n",
    "dt_val_mae = mean_absolute_error(y_val, y_val_pred_dt)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DECISION TREE REGRESSION - FINAL PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in dt_grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nTRAINING SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {dt_train_r2:.4f}\")\n",
    "print(f\"  RMSE:      {dt_train_rmse:.2f}\")\n",
    "print(f\"  MAE:       {dt_train_mae:.2f}\")\n",
    "\n",
    "print(\"\\nVALIDATION SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {dt_val_r2:.4f}\")\n",
    "print(f\"  RMSE:      {dt_val_rmse:.2f}\")\n",
    "print(f\"  MAE:       {dt_val_mae:.2f}\")\n",
    "\n",
    "print(f\"\\nOverfitting Gap: {abs(dt_train_r2 - dt_val_r2):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"FINAL SCORE (Validation R¬≤): {dt_val_r2:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fe7aa",
   "metadata": {},
   "source": [
    "## 25. Visualize Decision Tree Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00654148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Tree predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot - Validation Set\n",
    "axes[0].scatter(y_val, y_val_pred_dt, alpha=0.5, edgecolors='k', linewidth=0.5, color='darkgreen')\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Transport Cost', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[0].set_title(f'Decision Tree Regression: Actual vs Predicted\\nR¬≤ = {dt_val_r2:.4f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals_dt = y_val - y_val_pred_dt\n",
    "axes[1].scatter(y_val_pred_dt, residuals_dt, alpha=0.5, edgecolors='k', linewidth=0.5, color='brown')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot - Decision Tree (Validation Set)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print residual statistics\n",
    "print(\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean of Residuals:     {residuals_dt.mean():.4f}\")\n",
    "print(f\"  Std of Residuals:      {residuals_dt.std():.2f}\")\n",
    "print(f\"  Min Residual:          {residuals_dt.min():.2f}\")\n",
    "print(f\"  Max Residual:          {residuals_dt.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfadb80e",
   "metadata": {},
   "source": [
    "## 26. Analyze Top GridSearch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GridSearchCV results\n",
    "cv_results = pd.DataFrame(dt_grid_search.cv_results_)\n",
    "\n",
    "# Get top 10 parameter combinations\n",
    "top_10_results = cv_results.nlargest(10, 'mean_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TOP 10 DECISION TREE HYPERPARAMETER COMBINATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx, row in top_10_results.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
    "    print(f\"  Mean CV R¬≤ Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Parameters:\")\n",
    "    for param, value in row['params'].items():\n",
    "        print(f\"    {param}: {value}\")\n",
    "\n",
    "# Analyze parameter importance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PARAMETER ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show distribution of best parameters\n",
    "best_params = dt_grid_search.best_params_\n",
    "print(\"\\nOptimal Parameter Values:\")\n",
    "print(f\"  max_depth:          {best_params['max_depth']}\")\n",
    "print(f\"  min_samples_split:  {best_params['min_samples_split']}\")\n",
    "print(f\"  min_samples_leaf:   {best_params['min_samples_leaf']}\")\n",
    "print(f\"  max_leaf_nodes:     {best_params['max_leaf_nodes']}\")\n",
    "print(f\"  criterion:          {best_params['criterion']}\")\n",
    "print(f\"  max_features:       {best_params['max_features']}\")\n",
    "print(f\"  ccp_alpha:          {best_params['ccp_alpha']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GridSearchCV results for Gradient Boosting\n",
    "gb_cv_results = pd.DataFrame(gb_grid_search.cv_results_)\n",
    "\n",
    "# Get top 10 parameter combinations\n",
    "gb_top_10_results = gb_cv_results.nlargest(10, 'mean_test_score')[\n",
    "    ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TOP 10 GRADIENT BOOSTING HYPERPARAMETER COMBINATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx, row in gb_top_10_results.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}:\")\n",
    "    print(f\"  Mean CV R¬≤ Score: {row['mean_test_score']:.4f} (¬±{row['std_test_score']:.4f})\")\n",
    "    print(f\"  Parameters:\")\n",
    "    for param, value in row['params'].items():\n",
    "        print(f\"    {param}: {value}\")\n",
    "\n",
    "# Analyze parameter importance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMAL PARAMETER ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_gb_params = gb_grid_search.best_params_\n",
    "print(\"\\nOptimal Parameter Values:\")\n",
    "print(f\"  n_estimators:       {best_gb_params['n_estimators']}\")\n",
    "print(f\"  learning_rate:      {best_gb_params['learning_rate']}\")\n",
    "print(f\"  max_depth:          {best_gb_params['max_depth']}\")\n",
    "print(f\"  min_samples_split:  {best_gb_params['min_samples_split']}\")\n",
    "print(f\"  min_samples_leaf:   {best_gb_params['min_samples_leaf']}\")\n",
    "print(f\"  subsample:          {best_gb_params['subsample']}\")\n",
    "print(f\"  max_features:       {best_gb_params['max_features']}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE (Top 15)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_importance_gb = best_gb_model.feature_importances_\n",
    "feature_names_poly = [f\"Feature_{i}\" for i in range(len(feature_importance_gb))]\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names_poly,\n",
    "    'Importance': feature_importance_gb\n",
    "}).sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(15), importance_df['Importance'].values[::-1], color='teal', alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(15), importance_df['Feature'].values[::-1])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Gradient Boosting - Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e569a",
   "metadata": {},
   "source": [
    "## 30. Analyze Top Gradient Boosting GridSearch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Gradient Boosting predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot - Validation Set\n",
    "axes[0].scatter(y_val, y_val_pred_gb, alpha=0.5, edgecolors='k', linewidth=0.5, color='darkblue')\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Transport Cost', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[0].set_title(f'Gradient Boosting Regression: Actual vs Predicted\\nR¬≤ = {gb_val_r2:.4f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals_gb = y_val - y_val_pred_gb\n",
    "axes[1].scatter(y_val_pred_gb, residuals_gb, alpha=0.5, edgecolors='k', linewidth=0.5, color='teal')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Transport Cost', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot - Gradient Boosting (Validation Set)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print residual statistics\n",
    "print(\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean of Residuals:     {residuals_gb.mean():.4f}\")\n",
    "print(f\"  Std of Residuals:      {residuals_gb.std():.2f}\")\n",
    "print(f\"  Min Residual:          {residuals_gb.min():.2f}\")\n",
    "print(f\"  Max Residual:          {residuals_gb.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb113a",
   "metadata": {},
   "source": [
    "## 29. Visualize Gradient Boosting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_gb = best_gb_model.predict(X_train_poly)\n",
    "y_val_pred_gb = best_gb_model.predict(X_val_poly)\n",
    "\n",
    "# Calculate metrics\n",
    "gb_train_r2 = r2_score(y_train, y_train_pred_gb)\n",
    "gb_val_r2 = r2_score(y_val, y_val_pred_gb)\n",
    "gb_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_gb))\n",
    "gb_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_gb))\n",
    "gb_train_mae = mean_absolute_error(y_train, y_train_pred_gb)\n",
    "gb_val_mae = mean_absolute_error(y_val, y_val_pred_gb)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GRADIENT BOOSTING REGRESSION - FINAL PERFORMANCE METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in gb_grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nTRAINING SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {gb_train_r2:.4f}\")\n",
    "print(f\"  RMSE:      {gb_train_rmse:.2f}\")\n",
    "print(f\"  MAE:       {gb_train_mae:.2f}\")\n",
    "\n",
    "print(\"\\nVALIDATION SET METRICS:\")\n",
    "print(f\"  R¬≤ Score:  {gb_val_r2:.4f}\")\n",
    "print(f\"  RMSE:      {gb_val_rmse:.2f}\")\n",
    "print(f\"  MAE:       {gb_val_mae:.2f}\")\n",
    "\n",
    "print(f\"\\nOverfitting Gap: {abs(gb_train_r2 - gb_val_r2):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"FINAL SCORE (Validation R¬≤): {gb_val_r2:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78903a5f",
   "metadata": {},
   "source": [
    "## 28. Evaluate Best Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bff521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GRADIENT BOOSTING REGRESSION - HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUsing GridSearchCV for comprehensive hyperparameter optimization...\")\n",
    "\n",
    "# Define parameter grid for Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Use polynomial features for gradient boosting\n",
    "print(f\"Using Polynomial Features with Degree {int(best_degree)}\")\n",
    "print(f\"Training features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "# Initialize Gradient Boosting Regressor\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42, validation_fraction=0.1, n_iter_no_change=10)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "print(\"\\nPerforming GridSearchCV (this may take several minutes)...\")\n",
    "total_combinations = 4 * 4 * 4 * 3 * 3 * 4 * 3\n",
    "print(f\"Total combinations to test: {total_combinations}\")\n",
    "\n",
    "gb_grid_search = GridSearchCV(\n",
    "    estimator=gb_regressor,\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid_search.fit(X_train_poly, y_train)\n",
    "\n",
    "print(\"\\nGridSearchCV completed!\")\n",
    "print(f\"Best parameters found: {gb_grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation R¬≤ score: {gb_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e6468",
   "metadata": {},
   "source": [
    "## 27. Gradient Boosting Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf267eb",
   "metadata": {},
   "source": [
    "## 31. Train Final Best Regularized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2817ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models with best hyperparameters\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING FINAL REGULARIZED MODELS WITH BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ridge with best alpha\n",
    "final_ridge_model = Ridge(alpha=best_ridge_alpha, random_state=42)\n",
    "final_ridge_model.fit(X_train_poly, y_train)\n",
    "y_train_pred_ridge_final = final_ridge_model.predict(X_train_poly)\n",
    "y_val_pred_ridge_final = final_ridge_model.predict(X_val_poly)\n",
    "\n",
    "ridge_final_train_r2 = r2_score(y_train, y_train_pred_ridge_final)\n",
    "ridge_final_val_r2 = r2_score(y_val, y_val_pred_ridge_final)\n",
    "ridge_final_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_ridge_final))\n",
    "ridge_final_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_ridge_final))\n",
    "ridge_final_train_mae = mean_absolute_error(y_train, y_train_pred_ridge_final)\n",
    "ridge_final_val_mae = mean_absolute_error(y_val, y_val_pred_ridge_final)\n",
    "\n",
    "print(f\"\\nRidge Regression (Alpha={best_ridge_alpha}):\")\n",
    "print(f\"  Train R¬≤: {ridge_final_train_r2:.4f} | Val R¬≤: {ridge_final_val_r2:.4f}\")\n",
    "print(f\"  Train RMSE: {ridge_final_train_rmse:.2f} | Val RMSE: {ridge_final_val_rmse:.2f}\")\n",
    "print(f\"  Train MAE: {ridge_final_train_mae:.2f} | Val MAE: {ridge_final_val_mae:.2f}\")\n",
    "\n",
    "# Lasso with best alpha\n",
    "final_lasso_model = Lasso(alpha=best_lasso_alpha, random_state=42, max_iter=10000)\n",
    "final_lasso_model.fit(X_train_poly, y_train)\n",
    "y_train_pred_lasso_final = final_lasso_model.predict(X_train_poly)\n",
    "y_val_pred_lasso_final = final_lasso_model.predict(X_val_poly)\n",
    "\n",
    "lasso_final_train_r2 = r2_score(y_train, y_train_pred_lasso_final)\n",
    "lasso_final_val_r2 = r2_score(y_val, y_val_pred_lasso_final)\n",
    "lasso_final_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso_final))\n",
    "lasso_final_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_lasso_final))\n",
    "lasso_final_train_mae = mean_absolute_error(y_train, y_train_pred_lasso_final)\n",
    "lasso_final_val_mae = mean_absolute_error(y_val, y_val_pred_lasso_final)\n",
    "\n",
    "print(f\"\\nLasso Regression (Alpha={best_lasso_alpha}):\")\n",
    "print(f\"  Train R¬≤: {lasso_final_train_r2:.4f} | Val R¬≤: {lasso_final_val_r2:.4f}\")\n",
    "print(f\"  Train RMSE: {lasso_final_train_rmse:.2f} | Val RMSE: {lasso_final_val_rmse:.2f}\")\n",
    "print(f\"  Train MAE: {lasso_final_train_mae:.2f} | Val MAE: {lasso_final_val_mae:.2f}\")\n",
    "\n",
    "# ElasticNet with best alpha and l1_ratio\n",
    "final_elasticnet_model = ElasticNet(alpha=best_en_alpha, l1_ratio=best_en_l1_ratio, random_state=42, max_iter=10000)\n",
    "final_elasticnet_model.fit(X_train_poly, y_train)\n",
    "y_train_pred_en_final = final_elasticnet_model.predict(X_train_poly)\n",
    "y_val_pred_en_final = final_elasticnet_model.predict(X_val_poly)\n",
    "\n",
    "en_final_train_r2 = r2_score(y_train, y_train_pred_en_final)\n",
    "en_final_val_r2 = r2_score(y_val, y_val_pred_en_final)\n",
    "en_final_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_en_final))\n",
    "en_final_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_en_final))\n",
    "en_final_train_mae = mean_absolute_error(y_train, y_train_pred_en_final)\n",
    "en_final_val_mae = mean_absolute_error(y_val, y_val_pred_en_final)\n",
    "\n",
    "print(f\"\\nElasticNet Regression (Alpha={best_en_alpha}, L1_ratio={best_en_l1_ratio}):\")\n",
    "print(f\"  Train R¬≤: {en_final_train_r2:.4f} | Val R¬≤: {en_final_val_r2:.4f}\")\n",
    "print(f\"  Train RMSE: {en_final_train_rmse:.2f} | Val RMSE: {en_final_val_rmse:.2f}\")\n",
    "print(f\"  Train MAE: {en_final_train_mae:.2f} | Val MAE: {en_final_val_mae:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e2411",
   "metadata": {},
   "source": [
    "## 32. Comprehensive Model Comparison - All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40341a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison of all models\n",
    "all_models_comparison = {\n",
    "    'Model': [\n",
    "        'Linear Regression',\n",
    "        f'Polynomial Regression (Degree {int(best_degree)})',\n",
    "        f'Ridge (Œ±={best_ridge_alpha})',\n",
    "        f'Lasso (Œ±={best_lasso_alpha})',\n",
    "        f'ElasticNet (Œ±={best_en_alpha}, L1={best_en_l1_ratio})',\n",
    "        'Decision Tree (Tuned)',\n",
    "        'Gradient Boosting (Tuned)'\n",
    "    ],\n",
    "    'Train R¬≤': [\n",
    "        train_r2,\n",
    "        final_train_r2,\n",
    "        ridge_final_train_r2,\n",
    "        lasso_final_train_r2,\n",
    "        en_final_train_r2,\n",
    "        dt_train_r2,\n",
    "        gb_train_r2\n",
    "    ],\n",
    "    'Validation R¬≤': [\n",
    "        val_r2,\n",
    "        final_val_r2,\n",
    "        ridge_final_val_r2,\n",
    "        lasso_final_val_r2,\n",
    "        en_final_val_r2,\n",
    "        dt_val_r2,\n",
    "        gb_val_r2\n",
    "    ],\n",
    "    'Train RMSE': [\n",
    "        train_rmse,\n",
    "        final_train_rmse,\n",
    "        ridge_final_train_rmse,\n",
    "        lasso_final_train_rmse,\n",
    "        en_final_train_rmse,\n",
    "        dt_train_rmse,\n",
    "        gb_train_rmse\n",
    "    ],\n",
    "    'Validation RMSE': [\n",
    "        val_rmse,\n",
    "        final_val_rmse,\n",
    "        ridge_final_val_rmse,\n",
    "        lasso_final_val_rmse,\n",
    "        en_final_val_rmse,\n",
    "        dt_val_rmse,\n",
    "        gb_val_rmse\n",
    "    ],\n",
    "    'Train MAE': [\n",
    "        train_mae,\n",
    "        final_train_mae,\n",
    "        ridge_final_train_mae,\n",
    "        lasso_final_train_mae,\n",
    "        en_final_train_mae,\n",
    "        dt_train_mae,\n",
    "        gb_train_mae\n",
    "    ],\n",
    "    'Validation MAE': [\n",
    "        val_mae,\n",
    "        final_val_mae,\n",
    "        ridge_final_val_mae,\n",
    "        lasso_final_val_mae,\n",
    "        en_final_val_mae,\n",
    "        dt_val_mae,\n",
    "        gb_val_mae\n",
    "    ],\n",
    "    'Overfitting Gap': [\n",
    "        abs(train_r2 - val_r2),\n",
    "        abs(final_train_r2 - final_val_r2),\n",
    "        abs(ridge_final_train_r2 - ridge_final_val_r2),\n",
    "        abs(lasso_final_train_r2 - lasso_final_val_r2),\n",
    "        abs(en_final_train_r2 - en_final_val_r2),\n",
    "        abs(dt_train_r2 - dt_val_r2),\n",
    "        abs(gb_train_r2 - gb_val_r2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "all_models_df = pd.DataFrame(all_models_comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON - ALL REGRESSION MODELS\")\n",
    "print(\"=\"*100)\n",
    "print(all_models_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find the best model\n",
    "best_model_idx = all_models_df['Validation R¬≤'].idxmax()\n",
    "best_model_name = all_models_df.loc[best_model_idx, 'Model']\n",
    "best_model_val_r2 = all_models_df.loc[best_model_idx, 'Validation R¬≤']\n",
    "best_model_val_rmse = all_models_df.loc[best_model_idx, 'Validation RMSE']\n",
    "best_model_val_mae = all_models_df.loc[best_model_idx, 'Validation MAE']\n",
    "best_model_overfitting = all_models_df.loc[best_model_idx, 'Overfitting Gap']\n",
    "\n",
    "print(f\"\\nüèÜ BEST OVERALL MODEL: {best_model_name}\")\n",
    "print(\"=\"*100)\n",
    "print(f\"  Validation R¬≤ Score:    {best_model_val_r2:.4f}\")\n",
    "print(f\"  Validation RMSE:        {best_model_val_rmse:.2f}\")\n",
    "print(f\"  Validation MAE:         {best_model_val_mae:.2f}\")\n",
    "print(f\"  Overfitting Gap:        {best_model_overfitting:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72c532",
   "metadata": {},
   "source": [
    "## 33. Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison across all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Shorten model names for better visualization\n",
    "model_names_short = ['Linear', f'Poly-{int(best_degree)}', 'Ridge', 'Lasso', 'ElasticNet', 'DTree', 'GBoost']\n",
    "\n",
    "# Plot 1: Validation R¬≤ Comparison\n",
    "axes[0, 0].bar(model_names_short, all_models_df['Validation R¬≤'], \n",
    "               color=['steelblue', 'green', 'orange', 'red', 'purple', 'brown', 'darkblue'], \n",
    "               alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[0, 0].set_ylabel('Validation R¬≤ Score', fontsize=12)\n",
    "axes[0, 0].set_title('Model Comparison: Validation R¬≤ Score', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(all_models_df['Validation R¬≤']):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Validation RMSE Comparison\n",
    "axes[0, 1].bar(model_names_short, all_models_df['Validation RMSE'], \n",
    "               color=['steelblue', 'green', 'orange', 'red', 'purple', 'brown', 'darkblue'], \n",
    "               alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[0, 1].set_ylabel('Validation RMSE', fontsize=12)\n",
    "axes[0, 1].set_title('Model Comparison: Validation RMSE', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(all_models_df['Validation RMSE']):\n",
    "    axes[0, 1].text(i, v + 5, f'{v:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Plot 3: Validation MAE Comparison\n",
    "axes[1, 0].bar(model_names_short, all_models_df['Validation MAE'], \n",
    "               color=['steelblue', 'green', 'orange', 'red', 'purple', 'brown', 'darkblue'], \n",
    "               alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[1, 0].set_ylabel('Validation MAE', fontsize=12)\n",
    "axes[1, 0].set_title('Model Comparison: Validation MAE', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(all_models_df['Validation MAE']):\n",
    "    axes[1, 0].text(i, v + 3, f'{v:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Plot 4: Overfitting Gap Comparison\n",
    "axes[1, 1].bar(model_names_short, all_models_df['Overfitting Gap'], \n",
    "               color=['steelblue', 'green', 'orange', 'red', 'purple', 'brown', 'darkblue'], \n",
    "               alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[1, 1].axhline(y=0.05, color='red', linestyle='--', label='Acceptable threshold', linewidth=2)\n",
    "axes[1, 1].set_ylabel('|Train R¬≤ - Val R¬≤|', fontsize=12)\n",
    "axes[1, 1].set_title('Model Comparison: Overfitting Gap', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].legend()\n",
    "for i, v in enumerate(all_models_df['Overfitting Gap']):\n",
    "    axes[1, 1].text(i, v + 0.001, f'{v:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe9fdb",
   "metadata": {},
   "source": [
    "## 34. Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL SUMMARY - MEDICAL EQUIPMENT COST PREDICTION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nüìä DATA PREPROCESSING:\")\n",
    "print(f\"  ‚Ä¢ Original Training Samples: {len(train_df)}\")\n",
    "print(f\"  ‚Ä¢ Features Used: {X.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Polynomial Features Created: {X_train_poly.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Missing Values: Handled using Median (numerical) and Mode (categorical)\")\n",
    "print(f\"  ‚Ä¢ Outliers: Handled using IQR capping method\")\n",
    "print(f\"  ‚Ä¢ Feature Engineering: Delivery_Days, Equipment_Volume\")\n",
    "\n",
    "print(\"\\nüîß MODELS TESTED:\")\n",
    "print(\"  1. Linear Regression (Baseline)\")\n",
    "print(f\"  2. Polynomial Regression (Degree {int(best_degree)})\")\n",
    "print(f\"  3. Ridge Regression (Alpha={best_ridge_alpha})\")\n",
    "print(f\"  4. Lasso Regression (Alpha={best_lasso_alpha})\")\n",
    "print(f\"  5. ElasticNet Regression (Alpha={best_en_alpha}, L1_ratio={best_en_l1_ratio})\")\n",
    "print(f\"  6. Decision Tree Regression (Hyperparameter Tuned)\")\n",
    "print(f\"  7. Gradient Boosting Regression (Hyperparameter Tuned)\")\n",
    "\n",
    "print(\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "sorted_models = all_models_df.sort_values('Validation R¬≤', ascending=False)\n",
    "for idx, row in sorted_models.iterrows():\n",
    "    print(f\"\\n  {idx+1}. {row['Model']}\")\n",
    "    print(f\"     Val R¬≤: {row['Validation R¬≤']:.4f} | Val RMSE: {row['Validation RMSE']:.2f} | Val MAE: {row['Validation MAE']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"üèÜ RECOMMENDED MODEL: {best_model_name}\")\n",
    "print(\"=\"*100)\n",
    "print(f\"  ‚úì Validation R¬≤ Score:     {best_model_val_r2:.4f}\")\n",
    "print(f\"  ‚úì Validation RMSE:         {best_model_val_rmse:.2f}\")\n",
    "print(f\"  ‚úì Validation MAE:          {best_model_val_mae:.2f}\")\n",
    "print(f\"  ‚úì Overfitting Gap:         {best_model_overfitting:.4f}\")\n",
    "print(f\"  ‚úì Model explains {best_model_val_r2*100:.2f}% of variance in Transport Cost\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"  ‚Ä¢ Regularization helps prevent overfitting on polynomial features\")\n",
    "print(\"  ‚Ä¢ Gradient Boosting provides ensemble learning with sequential error correction\")\n",
    "print(\"  ‚Ä¢ The best model balances complexity and generalization\")\n",
    "print(\"  ‚Ä¢ Feature engineering significantly improved model performance\")\n",
    "print(\"  ‚Ä¢ Proper data preprocessing was crucial for model accuracy\")\n",
    "print(\"  ‚Ä¢ GridSearchCV systematically found optimal hyperparameters\")\n",
    "print(\"  ‚Ä¢ Ensemble methods (Gradient Boosting) often outperform single models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "\n",
    "print(\"=\"*100)print(\"Analysis Complete! ‚úÖ\")print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
